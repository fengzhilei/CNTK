CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 264172964 kB
-------------------------------------------------------------------
=== Running /home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/build/gpu/release/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/cntk_dpt.cntk currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/Data RunDir=/tmp/cntk-test-20161124192404.467155/Speech/DNN_DiscriminativePreTraining@release_gpu DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/Data ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining OutputDir=/tmp/cntk-test-20161124192404.467155/Speech/DNN_DiscriminativePreTraining@release_gpu DeviceId=0 timestamping=true
CNTK 2.0.beta4.0+ (HEAD a2a030, Nov 23 2016 18:33:12) on localhost at 2016/11/24 19:24:04

/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/build/gpu/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/cntk_dpt.cntk  currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/Data  RunDir=/tmp/cntk-test-20161124192404.467155/Speech/DNN_DiscriminativePreTraining@release_gpu  DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/Data  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining  OutputDir=/tmp/cntk-test-20161124192404.467155/Speech/DNN_DiscriminativePreTraining@release_gpu  DeviceId=0  timestamping=true
Changed current directory to /home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/Data
11/24/2016 19:24:05: -------------------------------------------------------------------
11/24/2016 19:24:05: Build info: 

11/24/2016 19:24:05: 		Built time: Nov 23 2016 18:33:12
11/24/2016 19:24:05: 		Last modified date: Wed Nov 23 18:30:09 2016
11/24/2016 19:24:05: 		Build type: release
11/24/2016 19:24:05: 		Build target: GPU
11/24/2016 19:24:05: 		With 1bit-SGD: no
11/24/2016 19:24:05: 		With ASGD: yes
11/24/2016 19:24:05: 		Math lib: mkl
11/24/2016 19:24:05: 		CUDA_PATH: /usr/local/cuda-8.0
11/24/2016 19:24:05: 		CUB_PATH: /usr/local/cub-1.4.1
11/24/2016 19:24:05: 		CUDNN_PATH: /usr/local
11/24/2016 19:24:05: 		Build Branch: HEAD
11/24/2016 19:24:05: 		Build SHA1: a2a0305b30713d3f8ade828ede1faa77d53665ac
11/24/2016 19:24:05: 		Built by Source/CNTK/buildinfo.h$$0 on c094ad5d9248
11/24/2016 19:24:05: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux-SlaveTest
11/24/2016 19:24:05: -------------------------------------------------------------------
11/24/2016 19:24:05: -------------------------------------------------------------------
11/24/2016 19:24:05: GPU info:

11/24/2016 19:24:05: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3020 MB
11/24/2016 19:24:05: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3020 MB
11/24/2016 19:24:05: -------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: cntk_dpt.cntk:addLayer2=[    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "/tmp/cntk-test-20161124192404.467155/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech"
    newModel  = "/tmp/cntk-test-20161124192404.467155/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech.0"
    editPath  = "/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/add_layer.mel"
]

configparameters: cntk_dpt.cntk:addLayer3=[    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "/tmp/cntk-test-20161124192404.467155/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech"
    newModel  = "/tmp/cntk-test-20161124192404.467155/Speech/DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.0"
    editPath  = "/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/add_layer.mel"
]

configparameters: cntk_dpt.cntk:command=dptPre1:addLayer2:dptPre2:addLayer3:speechTrain
configparameters: cntk_dpt.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining
configparameters: cntk_dpt.cntk:currentDirectory=/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/Data
configparameters: cntk_dpt.cntk:DataDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/Data
configparameters: cntk_dpt.cntk:deviceId=0
configparameters: cntk_dpt.cntk:dptPre1=[
    action = "train"
    modelPath = "/tmp/cntk-test-20161124192404.467155/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_dpt.cntk:dptPre2=[
    action = "train"
    modelPath = "/tmp/cntk-test-20161124192404.467155/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_dpt.cntk:globalInvStdPath=GlobalStats/var.363
configparameters: cntk_dpt.cntk:globalMeanPath=GlobalStats/mean.363
configparameters: cntk_dpt.cntk:globalPriorPath=GlobalStats/prior.132
configparameters: cntk_dpt.cntk:ndlMacros=/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/macros.txt
configparameters: cntk_dpt.cntk:OutputDir=/tmp/cntk-test-20161124192404.467155/Speech/DNN_DiscriminativePreTraining@release_gpu
configparameters: cntk_dpt.cntk:precision=float
configparameters: cntk_dpt.cntk:reader=[
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    useMersenneTwisterRand=true
    features = [
        dim = 363
        type = "real"
        scpFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/Data/glob_0000.scp"
    ]
    labels = [
        mlfFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/Data/glob_0000.mlf"
        labelMappingFile = "/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/Data/state.list"
        labelDim = 132
        labelType = "category"
    ]
]

configparameters: cntk_dpt.cntk:RunDir=/tmp/cntk-test-20161124192404.467155/Speech/DNN_DiscriminativePreTraining@release_gpu
configparameters: cntk_dpt.cntk:SGD=[
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]

configparameters: cntk_dpt.cntk:speechTrain=[
    action = "train"
    modelPath = "/tmp/cntk-test-20161124192404.467155/Speech/DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech"
    deviceId = 0
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/DNN/DiscriminativePreTraining/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]

configparameters: cntk_dpt.cntk:timestamping=true
configparameters: cntk_dpt.cntk:traceLevel=1
11/24/2016 19:24:05: Commands: dptPre1 addLayer2 dptPre2 addLayer3 speechTrain
11/24/2016 19:24:05: precision = "float"

11/24/2016 19:24:05: ##############################################################################
11/24/2016 19:24:05: #                                                                            #
11/24/2016 19:24:05: # dptPre1 command (train action)                                             #
11/24/2016 19:24:05: #                                                                            #
11/24/2016 19:24:05: ##############################################################################

11/24/2016 19:24:05: 
Creating virgin network.
NDLBuilder Using GPU 0
SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
reading script file /home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/Data/glob_0000.scp ... 948 entries
total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/Data/state.list
htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
11/24/2016 19:24:06: 
Model has 19 nodes. Using GPU 0.

11/24/2016 19:24:06: Training criterion:   ce = CrossEntropyWithSoftmax
11/24/2016 19:24:06: Evaluation criterion: err = ClassificationError


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 29 matrices, 11 are shared as 5, and 18 are not shared.

	{ HL1.z : [512 x 1 x *] (gradient)
	  OL.t : [132 x 1 x *] }
	{ HL1.W : [512 x 363] (gradient)
	  HL1.z : [512 x 1 x *] }
	{ HL1.b : [512 x 1] (gradient)
	  HL1.y : [512 x 1 x *] (gradient)
	  OL.z : [132 x 1 x *] (gradient) }
	{ OL.W : [132 x 512] (gradient)
	  OL.z : [132 x 1 x *] }
	{ HL1.t : [512 x *] (gradient)
	  HL1.y : [512 x 1 x *] }


11/24/2016 19:24:06: Training 254084 parameters in 4 out of 4 parameter tensors and 10 nodes with gradient:

11/24/2016 19:24:06: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
11/24/2016 19:24:06: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 19:24:06: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
11/24/2016 19:24:06: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

11/24/2016 19:24:06: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

11/24/2016 19:24:06: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

11/24/2016 19:24:06: Starting minibatch loop.
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.12%]: ce = 3.77545433 * 2560; err = 0.83984375 * 2560; time = 0.1322s; samplesPerSecond = 19365.5
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.92129173 * 2560; err = 0.69921875 * 2560; time = 0.0082s; samplesPerSecond = 312080.9
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.54243622 * 2560; err = 0.64882812 * 2560; time = 0.0080s; samplesPerSecond = 321527.3
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 2.20117416 * 2560; err = 0.60156250 * 2560; time = 0.0080s; samplesPerSecond = 318804.5
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.98474121 * 2560; err = 0.55273438 * 2560; time = 0.0080s; samplesPerSecond = 318408.0
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.87129364 * 2560; err = 0.51562500 * 2560; time = 0.0079s; samplesPerSecond = 322255.8
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.83400879 * 2560; err = 0.52812500 * 2560; time = 0.0079s; samplesPerSecond = 323927.6
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.71646271 * 2560; err = 0.49335937 * 2560; time = 0.0079s; samplesPerSecond = 322865.4
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.66541901 * 2560; err = 0.46328125 * 2560; time = 0.0083s; samplesPerSecond = 308954.9
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.57725983 * 2560; err = 0.46054688 * 2560; time = 0.0084s; samplesPerSecond = 305307.1
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.61621094 * 2560; err = 0.45390625 * 2560; time = 0.0084s; samplesPerSecond = 304798.2
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.56063995 * 2560; err = 0.44140625 * 2560; time = 0.0083s; samplesPerSecond = 307322.9
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.52853241 * 2560; err = 0.44492188 * 2560; time = 0.0084s; samplesPerSecond = 304870.8
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.53460999 * 2560; err = 0.46210937 * 2560; time = 0.0083s; samplesPerSecond = 306623.5
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.46377869 * 2560; err = 0.44140625 * 2560; time = 0.0084s; samplesPerSecond = 306440.0
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.43344116 * 2560; err = 0.42617187 * 2560; time = 0.0084s; samplesPerSecond = 306183.5
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.43215027 * 2560; err = 0.42148438 * 2560; time = 0.0084s; samplesPerSecond = 304544.4
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.37987366 * 2560; err = 0.41250000 * 2560; time = 0.0084s; samplesPerSecond = 305197.9
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.35841980 * 2560; err = 0.40039062 * 2560; time = 0.0085s; samplesPerSecond = 302743.6
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.44842224 * 2560; err = 0.42656250 * 2560; time = 0.0083s; samplesPerSecond = 307175.4
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.43927917 * 2560; err = 0.42539063 * 2560; time = 0.0083s; samplesPerSecond = 309365.6
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.41734009 * 2560; err = 0.42539063 * 2560; time = 0.0083s; samplesPerSecond = 309814.8
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.33211670 * 2560; err = 0.40468750 * 2560; time = 0.0082s; samplesPerSecond = 310378.3
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.36109009 * 2560; err = 0.40429688 * 2560; time = 0.0083s; samplesPerSecond = 306770.5
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.30958252 * 2560; err = 0.39804688 * 2560; time = 0.0083s; samplesPerSecond = 307064.9
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.25348511 * 2560; err = 0.36992188 * 2560; time = 0.0081s; samplesPerSecond = 314380.4
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.30338745 * 2560; err = 0.39570312 * 2560; time = 0.0089s; samplesPerSecond = 288711.0
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.36117859 * 2560; err = 0.40859375 * 2560; time = 0.0081s; samplesPerSecond = 317657.3
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.29568787 * 2560; err = 0.39531250 * 2560; time = 0.0079s; samplesPerSecond = 323804.7
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.35455017 * 2560; err = 0.40859375 * 2560; time = 0.0079s; samplesPerSecond = 322377.5
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.32246399 * 2560; err = 0.39921875 * 2560; time = 0.0078s; samplesPerSecond = 327952.9
11/24/2016 19:24:06:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.27023926 * 2560; err = 0.38242188 * 2560; time = 0.0080s; samplesPerSecond = 322012.6
11/24/2016 19:24:06: Finished Epoch[ 1 of 2]: [Training] ce = 1.65206318 * 81920; err = 0.46723633 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.473626s
11/24/2016 19:24:06: SGD: Saving checkpoint model '/tmp/cntk-test-20161124192404.467155/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech.1'

11/24/2016 19:24:06: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

11/24/2016 19:24:06: Starting minibatch loop.
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.12%]: ce = 1.24553871 * 2560; err = 0.38984375 * 2560; time = 0.0092s; samplesPerSecond = 277236.3
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.23801517 * 2560; err = 0.36718750 * 2560; time = 0.0080s; samplesPerSecond = 320761.8
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.26358624 * 2560; err = 0.39218750 * 2560; time = 0.0079s; samplesPerSecond = 325244.6
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.26325531 * 2560; err = 0.38203125 * 2560; time = 0.0079s; samplesPerSecond = 322865.4
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.27975998 * 2560; err = 0.36562500 * 2560; time = 0.0078s; samplesPerSecond = 328289.3
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.18315849 * 2560; err = 0.35195312 * 2560; time = 0.0079s; samplesPerSecond = 325907.1
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.19740906 * 2560; err = 0.37070313 * 2560; time = 0.0079s; samplesPerSecond = 324914.3
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.23275757 * 2560; err = 0.36835937 * 2560; time = 0.0078s; samplesPerSecond = 329514.7
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.27090912 * 2560; err = 0.38945313 * 2560; time = 0.0080s; samplesPerSecond = 318328.8
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.25143051 * 2560; err = 0.37500000 * 2560; time = 0.0078s; samplesPerSecond = 330067.0
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.21462936 * 2560; err = 0.37187500 * 2560; time = 0.0078s; samplesPerSecond = 328668.6
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.19433441 * 2560; err = 0.36796875 * 2560; time = 0.0089s; samplesPerSecond = 287769.8
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.16462097 * 2560; err = 0.36171875 * 2560; time = 0.0094s; samplesPerSecond = 272833.8
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.16609802 * 2560; err = 0.36484375 * 2560; time = 0.0083s; samplesPerSecond = 309029.5
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.14834595 * 2560; err = 0.34492187 * 2560; time = 0.0080s; samplesPerSecond = 321729.3
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.11703033 * 2560; err = 0.34804687 * 2560; time = 0.0080s; samplesPerSecond = 321891.1
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.17735901 * 2560; err = 0.35703125 * 2560; time = 0.0078s; samplesPerSecond = 326989.4
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.13435669 * 2560; err = 0.35664062 * 2560; time = 0.0079s; samplesPerSecond = 323354.8
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.14561310 * 2560; err = 0.35039063 * 2560; time = 0.0080s; samplesPerSecond = 320641.3
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.11020966 * 2560; err = 0.33281250 * 2560; time = 0.0079s; samplesPerSecond = 324338.0
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.16456146 * 2560; err = 0.35078125 * 2560; time = 0.0078s; samplesPerSecond = 326822.4
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.14552612 * 2560; err = 0.35742188 * 2560; time = 0.0078s; samplesPerSecond = 327659.0
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.09541931 * 2560; err = 0.34492187 * 2560; time = 0.0078s; samplesPerSecond = 329133.5
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.12883606 * 2560; err = 0.34218750 * 2560; time = 0.0080s; samplesPerSecond = 321769.7
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.08879089 * 2560; err = 0.33867188 * 2560; time = 0.0082s; samplesPerSecond = 313418.2
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.08555603 * 2560; err = 0.32695313 * 2560; time = 0.0083s; samplesPerSecond = 308768.5
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.12885132 * 2560; err = 0.34492187 * 2560; time = 0.0081s; samplesPerSecond = 314650.9
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.12917175 * 2560; err = 0.34921875 * 2560; time = 0.0081s; samplesPerSecond = 314999.4
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.12189331 * 2560; err = 0.34570312 * 2560; time = 0.0081s; samplesPerSecond = 315581.9
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.08549500 * 2560; err = 0.32773438 * 2560; time = 0.0080s; samplesPerSecond = 319122.4
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.08267212 * 2560; err = 0.34023437 * 2560; time = 0.0081s; samplesPerSecond = 317775.6
11/24/2016 19:24:06:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.07620239 * 2560; err = 0.32578125 * 2560; time = 0.0079s; samplesPerSecond = 325907.1
11/24/2016 19:24:06: Finished Epoch[ 2 of 2]: [Training] ce = 1.16660604 * 81920; err = 0.35634766 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.261508s
11/24/2016 19:24:06: SGD: Saving checkpoint model '/tmp/cntk-test-20161124192404.467155/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre1/cntkSpeech'

11/24/2016 19:24:06: Action "train" complete.


11/24/2016 19:24:06: ##############################################################################
11/24/2016 19:24:06: #                                                                            #
11/24/2016 19:24:06: # addLayer2 command (edit action)                                            #
11/24/2016 19:24:06: #                                                                            #
11/24/2016 19:24:06: ##############################################################################


11/24/2016 19:24:07: Action "edit" complete.


11/24/2016 19:24:07: ##############################################################################
11/24/2016 19:24:07: #                                                                            #
11/24/2016 19:24:07: # dptPre2 command (train action)                                             #
11/24/2016 19:24:07: #                                                                            #
11/24/2016 19:24:07: ##############################################################################

11/24/2016 19:24:07: 
Starting from checkpoint. Loading network from '/tmp/cntk-test-20161124192404.467155/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file /home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/Data/glob_0000.scp ... 948 entries
total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/Data/state.list
htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
11/24/2016 19:24:07: 
Model has 24 nodes. Using GPU 0.

11/24/2016 19:24:07: Training criterion:   ce = CrossEntropyWithSoftmax
11/24/2016 19:24:07: Evaluation criterion: err = ClassificationError

11/24/2016 19:24:07: Training 516740 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

11/24/2016 19:24:07: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
11/24/2016 19:24:07: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 19:24:07: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
11/24/2016 19:24:07: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 19:24:07: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
11/24/2016 19:24:07: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

11/24/2016 19:24:07: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

11/24/2016 19:24:07: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

11/24/2016 19:24:07: Starting minibatch loop.
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.12%]: ce = 3.86647491 * 2560; err = 0.82500000 * 2560; time = 0.0148s; samplesPerSecond = 173253.9
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.54898911 * 2560; err = 0.63476562 * 2560; time = 0.0114s; samplesPerSecond = 224109.3
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.14121246 * 2560; err = 0.57656250 * 2560; time = 0.0114s; samplesPerSecond = 224482.6
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.79803925 * 2560; err = 0.50039062 * 2560; time = 0.0114s; samplesPerSecond = 224325.3
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.61742325 * 2560; err = 0.46601562 * 2560; time = 0.0114s; samplesPerSecond = 224325.3
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.56606445 * 2560; err = 0.44296875 * 2560; time = 0.0114s; samplesPerSecond = 224837.5
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.56388550 * 2560; err = 0.45820312 * 2560; time = 0.0114s; samplesPerSecond = 224699.4
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.48627930 * 2560; err = 0.44257812 * 2560; time = 0.0114s; samplesPerSecond = 225153.9
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.43950348 * 2560; err = 0.42226562 * 2560; time = 0.0114s; samplesPerSecond = 224679.7
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.38922424 * 2560; err = 0.40820312 * 2560; time = 0.0117s; samplesPerSecond = 218262.4
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.41605225 * 2560; err = 0.40625000 * 2560; time = 0.0114s; samplesPerSecond = 224482.6
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.36434937 * 2560; err = 0.40156250 * 2560; time = 0.0114s; samplesPerSecond = 223913.2
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.32297516 * 2560; err = 0.39101562 * 2560; time = 0.0115s; samplesPerSecond = 222570.0
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.32911072 * 2560; err = 0.40820312 * 2560; time = 0.0114s; samplesPerSecond = 224089.6
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.27912140 * 2560; err = 0.38320312 * 2560; time = 0.0116s; samplesPerSecond = 219780.2
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.28819275 * 2560; err = 0.39101562 * 2560; time = 0.0115s; samplesPerSecond = 223522.2
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.29404297 * 2560; err = 0.38320312 * 2560; time = 0.0114s; samplesPerSecond = 224168.1
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.26791077 * 2560; err = 0.38750000 * 2560; time = 0.0114s; samplesPerSecond = 223991.6
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.29202576 * 2560; err = 0.38984375 * 2560; time = 0.0114s; samplesPerSecond = 223893.7
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.32967529 * 2560; err = 0.40351562 * 2560; time = 0.0114s; samplesPerSecond = 225114.3
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.31350403 * 2560; err = 0.39062500 * 2560; time = 0.0114s; samplesPerSecond = 225193.5
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.32099609 * 2560; err = 0.40117188 * 2560; time = 0.0114s; samplesPerSecond = 224364.6
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.23902588 * 2560; err = 0.37187500 * 2560; time = 0.0114s; samplesPerSecond = 224482.6
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.27047119 * 2560; err = 0.38476562 * 2560; time = 0.0114s; samplesPerSecond = 225233.2
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.22873535 * 2560; err = 0.37265625 * 2560; time = 0.0114s; samplesPerSecond = 225292.6
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.19374695 * 2560; err = 0.36093750 * 2560; time = 0.0114s; samplesPerSecond = 225074.7
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.20444031 * 2560; err = 0.37031250 * 2560; time = 0.0114s; samplesPerSecond = 225054.9
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.25301208 * 2560; err = 0.37421875 * 2560; time = 0.0114s; samplesPerSecond = 225510.9
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.17882996 * 2560; err = 0.34843750 * 2560; time = 0.0114s; samplesPerSecond = 224541.7
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.18337402 * 2560; err = 0.35312500 * 2560; time = 0.0114s; samplesPerSecond = 225193.5
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.19548645 * 2560; err = 0.36015625 * 2560; time = 0.0114s; samplesPerSecond = 225074.7
11/24/2016 19:24:07:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.15520325 * 2560; err = 0.34921875 * 2560; time = 0.0114s; samplesPerSecond = 224778.3
11/24/2016 19:24:07: Finished Epoch[ 1 of 2]: [Training] ce = 1.47929306 * 81920; err = 0.42374268 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.456779s
11/24/2016 19:24:07: SGD: Saving checkpoint model '/tmp/cntk-test-20161124192404.467155/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech.1'

11/24/2016 19:24:07: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

11/24/2016 19:24:07: Starting minibatch loop.
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.12%]: ce = 1.16795311 * 2560; err = 0.36523438 * 2560; time = 0.0126s; samplesPerSecond = 202692.0
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.19241753 * 2560; err = 0.35546875 * 2560; time = 0.0114s; samplesPerSecond = 224620.5
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.15635643 * 2560; err = 0.35546875 * 2560; time = 0.0114s; samplesPerSecond = 224817.8
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.15184097 * 2560; err = 0.35000000 * 2560; time = 0.0114s; samplesPerSecond = 224266.3
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.19516563 * 2560; err = 0.34882812 * 2560; time = 0.0114s; samplesPerSecond = 225332.3
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.13348312 * 2560; err = 0.34960938 * 2560; time = 0.0113s; samplesPerSecond = 225570.5
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.14547424 * 2560; err = 0.35351562 * 2560; time = 0.0114s; samplesPerSecond = 224817.8
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.16613235 * 2560; err = 0.36093750 * 2560; time = 0.0113s; samplesPerSecond = 225670.0
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.18128510 * 2560; err = 0.36640625 * 2560; time = 0.0113s; samplesPerSecond = 226008.7
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.19066391 * 2560; err = 0.35820313 * 2560; time = 0.0114s; samplesPerSecond = 224837.5
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.14411011 * 2560; err = 0.34335938 * 2560; time = 0.0114s; samplesPerSecond = 225332.3
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.14084778 * 2560; err = 0.34296875 * 2560; time = 0.0114s; samplesPerSecond = 224482.6
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.10022278 * 2560; err = 0.34140625 * 2560; time = 0.0114s; samplesPerSecond = 224089.6
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.12665253 * 2560; err = 0.35351562 * 2560; time = 0.0114s; samplesPerSecond = 224620.5
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.10091705 * 2560; err = 0.33632812 * 2560; time = 0.0114s; samplesPerSecond = 225530.8
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.07068024 * 2560; err = 0.33632812 * 2560; time = 0.0114s; samplesPerSecond = 224956.1
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.12074432 * 2560; err = 0.33476563 * 2560; time = 0.0114s; samplesPerSecond = 224344.9
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.07863770 * 2560; err = 0.32890625 * 2560; time = 0.0114s; samplesPerSecond = 225035.2
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.11367340 * 2560; err = 0.34648438 * 2560; time = 0.0114s; samplesPerSecond = 225352.1
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.08460999 * 2560; err = 0.32851562 * 2560; time = 0.0114s; samplesPerSecond = 224719.1
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.12654114 * 2560; err = 0.33437500 * 2560; time = 0.0114s; samplesPerSecond = 224364.6
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.09954987 * 2560; err = 0.33789062 * 2560; time = 0.0113s; samplesPerSecond = 225749.6
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.04854584 * 2560; err = 0.32851562 * 2560; time = 0.0114s; samplesPerSecond = 225213.3
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.10126953 * 2560; err = 0.34140625 * 2560; time = 0.0114s; samplesPerSecond = 225292.6
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.09957275 * 2560; err = 0.34023437 * 2560; time = 0.0114s; samplesPerSecond = 224561.4
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.07384949 * 2560; err = 0.32695313 * 2560; time = 0.0114s; samplesPerSecond = 224443.3
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.10745239 * 2560; err = 0.33867188 * 2560; time = 0.0114s; samplesPerSecond = 225272.8
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.08762207 * 2560; err = 0.34062500 * 2560; time = 0.0114s; samplesPerSecond = 224719.1
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.10357056 * 2560; err = 0.34218750 * 2560; time = 0.0114s; samplesPerSecond = 224995.6
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.09004517 * 2560; err = 0.32968750 * 2560; time = 0.0114s; samplesPerSecond = 224581.1
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.08311157 * 2560; err = 0.33750000 * 2560; time = 0.0114s; samplesPerSecond = 224817.8
11/24/2016 19:24:07:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.06857605 * 2560; err = 0.32968750 * 2560; time = 0.0113s; samplesPerSecond = 225729.7
11/24/2016 19:24:07: Finished Epoch[ 2 of 2]: [Training] ce = 1.12036171 * 81920; err = 0.34324951 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.368677s
11/24/2016 19:24:07: SGD: Saving checkpoint model '/tmp/cntk-test-20161124192404.467155/Speech/DNN_DiscriminativePreTraining@release_gpu/models/Pre2/cntkSpeech'

11/24/2016 19:24:08: Action "train" complete.


11/24/2016 19:24:08: ##############################################################################
11/24/2016 19:24:08: #                                                                            #
11/24/2016 19:24:08: # addLayer3 command (edit action)                                            #
11/24/2016 19:24:08: #                                                                            #
11/24/2016 19:24:08: ##############################################################################


11/24/2016 19:24:08: Action "edit" complete.


11/24/2016 19:24:08: ##############################################################################
11/24/2016 19:24:08: #                                                                            #
11/24/2016 19:24:08: # speechTrain command (train action)                                         #
11/24/2016 19:24:08: #                                                                            #
11/24/2016 19:24:08: ##############################################################################

11/24/2016 19:24:08: 
Starting from checkpoint. Loading network from '/tmp/cntk-test-20161124192404.467155/Speech/DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file /home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/Data/glob_0000.scp ... 948 entries
total 132 state names in state list /home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/Data/state.list
htkmlfreader: reading MLF file /home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/Data/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
11/24/2016 19:24:08: 
Model has 29 nodes. Using GPU 0.

11/24/2016 19:24:08: Training criterion:   ce = CrossEntropyWithSoftmax
11/24/2016 19:24:08: Evaluation criterion: err = ClassificationError

11/24/2016 19:24:08: Training 779396 parameters in 8 out of 8 parameter tensors and 20 nodes with gradient:

11/24/2016 19:24:08: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
11/24/2016 19:24:08: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 19:24:08: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
11/24/2016 19:24:08: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 19:24:08: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
11/24/2016 19:24:08: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 19:24:08: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
11/24/2016 19:24:08: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

11/24/2016 19:24:08: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

11/24/2016 19:24:08: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900117  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

11/24/2016 19:24:08: Starting minibatch loop.
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[   1-  10, 3.12%]: ce = 4.04677773 * 2560; err = 0.83906250 * 2560; time = 0.0194s; samplesPerSecond = 132210.9
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[  11-  20, 6.25%]: ce = 2.54597816 * 2560; err = 0.61093750 * 2560; time = 0.0155s; samplesPerSecond = 164662.0
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[  21-  30, 9.38%]: ce = 2.03924866 * 2560; err = 0.55781250 * 2560; time = 0.0155s; samplesPerSecond = 165076.1
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[  31-  40, 12.50%]: ce = 1.68576508 * 2560; err = 0.46992187 * 2560; time = 0.0155s; samplesPerSecond = 165097.4
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[  41-  50, 15.62%]: ce = 1.50976562 * 2560; err = 0.43476562 * 2560; time = 0.0156s; samplesPerSecond = 163787.6
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[  51-  60, 18.75%]: ce = 1.45761642 * 2560; err = 0.42148438 * 2560; time = 0.0155s; samplesPerSecond = 164959.1
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[  61-  70, 21.88%]: ce = 1.45345001 * 2560; err = 0.42265625 * 2560; time = 0.0156s; samplesPerSecond = 164598.5
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[  71-  80, 25.00%]: ce = 1.37162476 * 2560; err = 0.40234375 * 2560; time = 0.0155s; samplesPerSecond = 165065.4
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[  81-  90, 28.12%]: ce = 1.32944489 * 2560; err = 0.38632813 * 2560; time = 0.0156s; samplesPerSecond = 163965.9
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[  91- 100, 31.25%]: ce = 1.28814087 * 2560; err = 0.38476562 * 2560; time = 0.0156s; samplesPerSecond = 164144.7
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[ 101- 110, 34.38%]: ce = 1.31804657 * 2560; err = 0.38281250 * 2560; time = 0.0156s; samplesPerSecond = 164313.2
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[ 111- 120, 37.50%]: ce = 1.27836304 * 2560; err = 0.37929687 * 2560; time = 0.0156s; samplesPerSecond = 164556.1
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[ 121- 130, 40.62%]: ce = 1.24774475 * 2560; err = 0.37578125 * 2560; time = 0.0156s; samplesPerSecond = 164313.2
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[ 131- 140, 43.75%]: ce = 1.25934601 * 2560; err = 0.38867188 * 2560; time = 0.0156s; samplesPerSecond = 164323.8
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[ 141- 150, 46.88%]: ce = 1.20145721 * 2560; err = 0.35703125 * 2560; time = 0.0156s; samplesPerSecond = 163829.5
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[ 151- 160, 50.00%]: ce = 1.21967773 * 2560; err = 0.36953125 * 2560; time = 0.0156s; samplesPerSecond = 163850.5
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[ 161- 170, 53.12%]: ce = 1.21199951 * 2560; err = 0.36015625 * 2560; time = 0.0156s; samplesPerSecond = 164144.7
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[ 171- 180, 56.25%]: ce = 1.19965210 * 2560; err = 0.37109375 * 2560; time = 0.0156s; samplesPerSecond = 163882.0
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[ 181- 190, 59.38%]: ce = 1.22144470 * 2560; err = 0.36953125 * 2560; time = 0.0156s; samplesPerSecond = 164239.4
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[ 191- 200, 62.50%]: ce = 1.25665588 * 2560; err = 0.37734375 * 2560; time = 0.0157s; samplesPerSecond = 163182.0
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[ 201- 210, 65.62%]: ce = 1.24638977 * 2560; err = 0.36679688 * 2560; time = 0.0156s; samplesPerSecond = 164566.7
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[ 211- 220, 68.75%]: ce = 1.25676575 * 2560; err = 0.38906250 * 2560; time = 0.0156s; samplesPerSecond = 163882.0
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[ 221- 230, 71.88%]: ce = 1.17662964 * 2560; err = 0.35234375 * 2560; time = 0.0156s; samplesPerSecond = 164281.6
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[ 231- 240, 75.00%]: ce = 1.21300354 * 2560; err = 0.37773438 * 2560; time = 0.0156s; samplesPerSecond = 164186.8
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[ 241- 250, 78.12%]: ce = 1.17398071 * 2560; err = 0.35664062 * 2560; time = 0.0156s; samplesPerSecond = 164144.7
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[ 251- 260, 81.25%]: ce = 1.14210815 * 2560; err = 0.33867188 * 2560; time = 0.0156s; samplesPerSecond = 163861.0
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[ 261- 270, 84.38%]: ce = 1.13465271 * 2560; err = 0.35273437 * 2560; time = 0.0156s; samplesPerSecond = 164260.5
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[ 271- 280, 87.50%]: ce = 1.19354248 * 2560; err = 0.36054687 * 2560; time = 0.0156s; samplesPerSecond = 164492.7
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[ 281- 290, 90.62%]: ce = 1.12551880 * 2560; err = 0.33437500 * 2560; time = 0.0156s; samplesPerSecond = 163745.7
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[ 291- 300, 93.75%]: ce = 1.14223633 * 2560; err = 0.35390625 * 2560; time = 0.0156s; samplesPerSecond = 164144.7
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[ 301- 310, 96.88%]: ce = 1.14798279 * 2560; err = 0.35078125 * 2560; time = 0.0156s; samplesPerSecond = 164334.3
11/24/2016 19:24:08:  Epoch[ 1 of 4]-Minibatch[ 311- 320, 100.00%]: ce = 1.11043396 * 2560; err = 0.33281250 * 2560; time = 0.0156s; samplesPerSecond = 163714.3
11/24/2016 19:24:08: Finished Epoch[ 1 of 4]: [Training] ce = 1.41267014 * 81920; err = 0.40399170 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.585747s
11/24/2016 19:24:08: SGD: Saving checkpoint model '/tmp/cntk-test-20161124192404.467155/Speech/DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.1'

11/24/2016 19:24:08: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

11/24/2016 19:24:08: Starting minibatch loop.
11/24/2016 19:24:08:  Epoch[ 2 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.20851707 * 5120; err = 0.37148437 * 5120; time = 0.0280s; samplesPerSecond = 182759.2
11/24/2016 19:24:08:  Epoch[ 2 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.60702591 * 5120; err = 0.42792969 * 5120; time = 0.0242s; samplesPerSecond = 211160.1
11/24/2016 19:24:08:  Epoch[ 2 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.29681091 * 5120; err = 0.38671875 * 5120; time = 0.0243s; samplesPerSecond = 210942.6
11/24/2016 19:24:08:  Epoch[ 2 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.15652657 * 5120; err = 0.35019531 * 5120; time = 0.0244s; samplesPerSecond = 210068.5
11/24/2016 19:24:08:  Epoch[ 2 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.16663971 * 5120; err = 0.35371094 * 5120; time = 0.0243s; samplesPerSecond = 210795.0
11/24/2016 19:24:08:  Epoch[ 2 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.12503662 * 5120; err = 0.34003906 * 5120; time = 0.0242s; samplesPerSecond = 211421.7
11/24/2016 19:24:08:  Epoch[ 2 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.10204163 * 5120; err = 0.34492187 * 5120; time = 0.0243s; samplesPerSecond = 210994.8
11/24/2016 19:24:09:  Epoch[ 2 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.06863632 * 5120; err = 0.33261719 * 5120; time = 0.0243s; samplesPerSecond = 211081.8
11/24/2016 19:24:09:  Epoch[ 2 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.09265671 * 5120; err = 0.33105469 * 5120; time = 0.0243s; samplesPerSecond = 210743.0
11/24/2016 19:24:09:  Epoch[ 2 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.10557861 * 5120; err = 0.34453125 * 5120; time = 0.0243s; samplesPerSecond = 210855.8
11/24/2016 19:24:09:  Epoch[ 2 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.09812393 * 5120; err = 0.33437500 * 5120; time = 0.0242s; samplesPerSecond = 211797.8
11/24/2016 19:24:09:  Epoch[ 2 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.08034668 * 5120; err = 0.33808594 * 5120; time = 0.0241s; samplesPerSecond = 212518.7
11/24/2016 19:24:09:  Epoch[ 2 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.07839813 * 5120; err = 0.33476563 * 5120; time = 0.0241s; samplesPerSecond = 212210.4
11/24/2016 19:24:09:  Epoch[ 2 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.13334656 * 5120; err = 0.34472656 * 5120; time = 0.0242s; samplesPerSecond = 211876.7
11/24/2016 19:24:09:  Epoch[ 2 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.07234039 * 5120; err = 0.32500000 * 5120; time = 0.0243s; samplesPerSecond = 210769.0
11/24/2016 19:24:09:  Epoch[ 2 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.04175415 * 5120; err = 0.31796875 * 5120; time = 0.0243s; samplesPerSecond = 210942.6
11/24/2016 19:24:09: Finished Epoch[ 2 of 4]: [Training] ce = 1.15211124 * 81920; err = 0.34863281 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.395502s
11/24/2016 19:24:09: SGD: Saving checkpoint model '/tmp/cntk-test-20161124192404.467155/Speech/DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.2'

11/24/2016 19:24:09: Starting Epoch 3: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 163840), data subset 0 of 1, with 1 datapasses

11/24/2016 19:24:09: Starting minibatch loop.
11/24/2016 19:24:09:  Epoch[ 3 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.06754780 * 5120; err = 0.33203125 * 5120; time = 0.0252s; samplesPerSecond = 203303.7
11/24/2016 19:24:09:  Epoch[ 3 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.10302010 * 5120; err = 0.33710937 * 5120; time = 0.0243s; samplesPerSecond = 210934.0
11/24/2016 19:24:09:  Epoch[ 3 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.09730244 * 5120; err = 0.34042969 * 5120; time = 0.0243s; samplesPerSecond = 210664.9
11/24/2016 19:24:09:  Epoch[ 3 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.05428734 * 5120; err = 0.32636719 * 5120; time = 0.0244s; samplesPerSecond = 209999.6
11/24/2016 19:24:09:  Epoch[ 3 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.07071533 * 5120; err = 0.32363281 * 5120; time = 0.0243s; samplesPerSecond = 210526.3
11/24/2016 19:24:09:  Epoch[ 3 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.07910347 * 5120; err = 0.32890625 * 5120; time = 0.0243s; samplesPerSecond = 210664.9
11/24/2016 19:24:09:  Epoch[ 3 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.07294006 * 5120; err = 0.33730469 * 5120; time = 0.0242s; samplesPerSecond = 211282.1
11/24/2016 19:24:09:  Epoch[ 3 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.07958755 * 5120; err = 0.34101562 * 5120; time = 0.0243s; samplesPerSecond = 210890.5
11/24/2016 19:24:09:  Epoch[ 3 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.08957214 * 5120; err = 0.34628906 * 5120; time = 0.0242s; samplesPerSecond = 211360.6
11/24/2016 19:24:09:  Epoch[ 3 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.02898560 * 5120; err = 0.31972656 * 5120; time = 0.0242s; samplesPerSecond = 211177.6
11/24/2016 19:24:09:  Epoch[ 3 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.03700180 * 5120; err = 0.32500000 * 5120; time = 0.0243s; samplesPerSecond = 210968.7
11/24/2016 19:24:09:  Epoch[ 3 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.05457993 * 5120; err = 0.32558594 * 5120; time = 0.0243s; samplesPerSecond = 210786.3
11/24/2016 19:24:09:  Epoch[ 3 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.06231384 * 5120; err = 0.33613281 * 5120; time = 0.0242s; samplesPerSecond = 211195.0
11/24/2016 19:24:09:  Epoch[ 3 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.09723053 * 5120; err = 0.35000000 * 5120; time = 0.0243s; samplesPerSecond = 210708.3
11/24/2016 19:24:09:  Epoch[ 3 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.02479858 * 5120; err = 0.31601563 * 5120; time = 0.0242s; samplesPerSecond = 211186.3
11/24/2016 19:24:09:  Epoch[ 3 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.03645782 * 5120; err = 0.32753906 * 5120; time = 0.0243s; samplesPerSecond = 210934.0
11/24/2016 19:24:09: Finished Epoch[ 3 of 4]: [Training] ce = 1.06596527 * 81920; err = 0.33206787 * 81920; totalSamplesSeen = 245760; learningRatePerSample = 0.003125; epochTime=0.392958s
11/24/2016 19:24:09: SGD: Saving checkpoint model '/tmp/cntk-test-20161124192404.467155/Speech/DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech.3'

11/24/2016 19:24:09: Starting Epoch 4: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 3: frames [245760..327680] (first utterance at frame 245760), data subset 0 of 1, with 1 datapasses

11/24/2016 19:24:09: Starting minibatch loop.
11/24/2016 19:24:09:  Epoch[ 4 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.02215757 * 5120; err = 0.32792969 * 5120; time = 0.0252s; samplesPerSecond = 203408.7
11/24/2016 19:24:09:  Epoch[ 4 of 4]-Minibatch[  11-  20, 12.50%]: ce = 0.99789512 * 4926; err = 0.31120585 * 4926; time = 0.0489s; samplesPerSecond = 100765.0
11/24/2016 19:24:09:  Epoch[ 4 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.02274361 * 5120; err = 0.32304688 * 5120; time = 0.0243s; samplesPerSecond = 210595.6
11/24/2016 19:24:09:  Epoch[ 4 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.03222694 * 5120; err = 0.32089844 * 5120; time = 0.0243s; samplesPerSecond = 210847.1
11/24/2016 19:24:09:  Epoch[ 4 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.02917290 * 5120; err = 0.31933594 * 5120; time = 0.0244s; samplesPerSecond = 210249.7
11/24/2016 19:24:09:  Epoch[ 4 of 4]-Minibatch[  51-  60, 37.50%]: ce = 0.99437828 * 5120; err = 0.31660156 * 5120; time = 0.0242s; samplesPerSecond = 211308.3
11/24/2016 19:24:09:  Epoch[ 4 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.01083527 * 5120; err = 0.31445312 * 5120; time = 0.0243s; samplesPerSecond = 211099.2
11/24/2016 19:24:09:  Epoch[ 4 of 4]-Minibatch[  71-  80, 50.00%]: ce = 0.99924469 * 5120; err = 0.30781250 * 5120; time = 0.0243s; samplesPerSecond = 210994.8
11/24/2016 19:24:09:  Epoch[ 4 of 4]-Minibatch[  81-  90, 56.25%]: ce = 0.97666321 * 5120; err = 0.31953125 * 5120; time = 0.0243s; samplesPerSecond = 210786.3
11/24/2016 19:24:09:  Epoch[ 4 of 4]-Minibatch[  91- 100, 62.50%]: ce = 0.98095627 * 5120; err = 0.30214844 * 5120; time = 0.0243s; samplesPerSecond = 211064.4
11/24/2016 19:24:10:  Epoch[ 4 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.03339462 * 5120; err = 0.31718750 * 5120; time = 0.0243s; samplesPerSecond = 210821.0
11/24/2016 19:24:10:  Epoch[ 4 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 0.97907867 * 5120; err = 0.30410156 * 5120; time = 0.0243s; samplesPerSecond = 210743.0
11/24/2016 19:24:10:  Epoch[ 4 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 0.99901123 * 5120; err = 0.31230469 * 5120; time = 0.0243s; samplesPerSecond = 210604.3
11/24/2016 19:24:10:  Epoch[ 4 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 0.96658020 * 5120; err = 0.30019531 * 5120; time = 0.0242s; samplesPerSecond = 211360.6
11/24/2016 19:24:10:  Epoch[ 4 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 0.97358246 * 5120; err = 0.30195312 * 5120; time = 0.0243s; samplesPerSecond = 211081.8
11/24/2016 19:24:10:  Epoch[ 4 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 0.96887970 * 5120; err = 0.30585937 * 5120; time = 0.0244s; samplesPerSecond = 210120.2
11/24/2016 19:24:10: Finished Epoch[ 4 of 4]: [Training] ce = 0.99941750 * 81920; err = 0.31286621 * 81920; totalSamplesSeen = 327680; learningRatePerSample = 0.003125; epochTime=0.419244s
11/24/2016 19:24:10: SGD: Saving checkpoint model '/tmp/cntk-test-20161124192404.467155/Speech/DNN_DiscriminativePreTraining@release_gpu/models/cntkSpeech'

11/24/2016 19:24:10: Action "train" complete.

11/24/2016 19:24:10: __COMPLETED__