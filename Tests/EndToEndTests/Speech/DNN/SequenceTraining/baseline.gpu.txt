CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 264172964 kB
-------------------------------------------------------------------
=== Running /home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/build/gpu/release/bin/cntk configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/DNN/SequenceTraining/cntk_sequence.cntk currentDirectory=/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData RunDir=/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu DataDir=/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/DNN/SequenceTraining OutputDir=/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu DeviceId=0 timestamping=true
CNTK 2.0.beta4.0+ (HEAD a2a030, Nov 23 2016 18:33:12) on localhost at 2016/11/24 19:24:10

/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/build/gpu/release/bin/cntk  configFile=/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/DNN/SequenceTraining/cntk_sequence.cntk  currentDirectory=/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData  RunDir=/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu  DataDir=/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData  ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/DNN/SequenceTraining  OutputDir=/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu  DeviceId=0  timestamping=true
Changed current directory to /tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData
11/24/2016 19:24:11: -------------------------------------------------------------------
11/24/2016 19:24:11: Build info: 

11/24/2016 19:24:11: 		Built time: Nov 23 2016 18:33:12
11/24/2016 19:24:11: 		Last modified date: Wed Nov 23 18:30:09 2016
11/24/2016 19:24:11: 		Build type: release
11/24/2016 19:24:11: 		Build target: GPU
11/24/2016 19:24:11: 		With 1bit-SGD: no
11/24/2016 19:24:11: 		With ASGD: yes
11/24/2016 19:24:11: 		Math lib: mkl
11/24/2016 19:24:11: 		CUDA_PATH: /usr/local/cuda-8.0
11/24/2016 19:24:11: 		CUB_PATH: /usr/local/cub-1.4.1
11/24/2016 19:24:11: 		CUDNN_PATH: /usr/local
11/24/2016 19:24:11: 		Build Branch: HEAD
11/24/2016 19:24:11: 		Build SHA1: a2a0305b30713d3f8ade828ede1faa77d53665ac
11/24/2016 19:24:11: 		Built by Source/CNTK/buildinfo.h$$0 on c094ad5d9248
11/24/2016 19:24:11: 		Build Path: /home/philly/jenkins/workspace/CNTK-Build-Linux-SlaveTest
11/24/2016 19:24:11: -------------------------------------------------------------------
11/24/2016 19:24:12: -------------------------------------------------------------------
11/24/2016 19:24:12: GPU info:

11/24/2016 19:24:12: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3020 MB
11/24/2016 19:24:12: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3020 MB
11/24/2016 19:24:12: -------------------------------------------------------------------

Configuration After Processing and Variable Resolution:

configparameters: cntk_sequence.cntk:addLayer2=[    
    action = "edit"
    currLayer = 1
    newLayer = 2
    currModel = "/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech"
    newModel  = "/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech.0"
    editPath  = "/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/DNN/SequenceTraining/add_layer.mel"
]

configparameters: cntk_sequence.cntk:AddLayer3=[    
    action = "edit"
    currLayer = 2
    newLayer = 3
    currModel = "/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech"
    newModel  = "/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.0"
    editPath  = "/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/DNN/SequenceTraining/add_layer.mel"
]

configparameters: cntk_sequence.cntk:command=dptPre1:addLayer2:dptPre2:addLayer3:speechTrain:replaceCriterionNode:sequenceTrain
configparameters: cntk_sequence.cntk:ConfigDir=/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/DNN/SequenceTraining
configparameters: cntk_sequence.cntk:currentDirectory=/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData
configparameters: cntk_sequence.cntk:DataDir=/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData
configparameters: cntk_sequence.cntk:deviceId=0
configparameters: cntk_sequence.cntk:dptPre1=[
    action = "train"
    modelPath = "/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/DNN/SequenceTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_sequence.cntk:dptPre2=[
    action = "train"
    modelPath = "/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech"
    NDLNetworkBuilder = [
        networkDescription = "/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/DNN/SequenceTraining/dnn_1layer.txt"
    ]
]

configparameters: cntk_sequence.cntk:globalInvStdPath=GlobalStats/var.363
configparameters: cntk_sequence.cntk:globalMeanPath=GlobalStats/mean.363
configparameters: cntk_sequence.cntk:globalPriorPath=GlobalStats/prior.132
configparameters: cntk_sequence.cntk:ndlMacros=/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/DNN/SequenceTraining/macros.txt
configparameters: cntk_sequence.cntk:OutputDir=/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu
configparameters: cntk_sequence.cntk:precision=float
configparameters: cntk_sequence.cntk:reader=[
    readerType = "HTKMLFReader"
    readMethod = "blockRandomize"
    miniBatchMode = "partial"
    randomize = "auto"
    verbosity = 0
    features = [
        dim = 363
        type = "real"
        scpFile = "/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.scp"
    ]
    labels = [
        mlfFile = "/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.mlf"
        labelMappingFile = "/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData/state.list"
        labelDim = 132
        labelType = "category"
    ]
]

configparameters: cntk_sequence.cntk:replaceCriterionNode=[
    action = "edit"
    currModel = "/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech"
    newModel  = "/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.0"
    editPath  = "/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/DNN/SequenceTraining/replace_ce_with_sequence_criterion.mel"
]

configparameters: cntk_sequence.cntk:RunDir=/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu
configparameters: cntk_sequence.cntk:sequenceTrain=[
    action = "train"
    modelPath = "/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/DNN/SequenceTraining/nonexistentfile.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 10
        learningRatesPerSample = 0.000002
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 3
        hsmoothingWeight = 0.95
        frameDropThresh = 1e-10
        numMBsToShowResult = 10
        gradientClippingWithTruncation = true
        clippingThresholdPerSample = 1.0
    ]
    reader = [
        readerType = "HTKMLFReader"
        readMethod = "blockRandomize"
        frameMode = false
        nbruttsineachrecurrentiter = 2
        miniBatchMode = "partial"
        randomize = "auto"
        verbosity = 0
        features = [
            dim = 363
            type = "real"
            scpFile = "/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.scp"
        ]
        labels = [
            mlfFile = "/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.mlf"
            labelMappingFile = "/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData/state.list"
            labelDim = 132
            labelType = "category"
        ]
        hmms = [
            phoneFile  = "/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData/model.overalltying"
            transpFile = "/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData/model.transprob"
        ]
        lattices = [
            denlatTocFile = "/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData/*.lats.toc"
        ]
    ]
]

configparameters: cntk_sequence.cntk:SGD=[
    epochSize = 81920
    minibatchSize = 256
    learningRatesPerMB = 0.8
    numMBsToShowResult = 10
    momentumPerMB = 0.9
    dropoutRate = 0.0
    maxEpochs = 2
]

configparameters: cntk_sequence.cntk:speechTrain=[
    action = "train"
    modelPath = "/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech"
    traceLevel = 1
    NDLNetworkBuilder = [
        networkDescription = "/home/philly/jenkins/workspace/CNTK-Test-Linux-SlaveTest/Tests/EndToEndTests/Speech/DNN/SequenceTraining/dnn.txt"
    ]
    SGD = [
        epochSize = 81920
        minibatchSize = 256:512
        learningRatesPerMB = 0.8:1.6
        numMBsToShowResult = 10
        momentumPerSample = 0.999589
        dropoutRate = 0.0
        maxEpochs = 4
        gradUpdateType = "none"
        normWithAveMultiplier = true
        clippingThresholdPerSample = 1#INF
    ]
]

configparameters: cntk_sequence.cntk:timestamping=true
configparameters: cntk_sequence.cntk:traceLevel=1
configparameters: cntk_sequence.cntk:truncated=false
11/24/2016 19:24:12: Commands: dptPre1 addLayer2 dptPre2 addLayer3 speechTrain replaceCriterionNode sequenceTrain
11/24/2016 19:24:12: precision = "float"

11/24/2016 19:24:12: ##############################################################################
11/24/2016 19:24:12: #                                                                            #
11/24/2016 19:24:12: # dptPre1 command (train action)                                             #
11/24/2016 19:24:12: #                                                                            #
11/24/2016 19:24:12: ##############################################################################

11/24/2016 19:24:12: 
Creating virgin network.
NDLBuilder Using GPU 0
SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==4
reading script file /tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.scp ... 948 entries
total 132 state names in state list /tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData/state.list
htkmlfreader: reading MLF file /tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
11/24/2016 19:24:12: 
Model has 19 nodes. Using GPU 0.

11/24/2016 19:24:12: Training criterion:   ce = CrossEntropyWithSoftmax
11/24/2016 19:24:12: Evaluation criterion: err = ClassificationError


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 29 matrices, 11 are shared as 5, and 18 are not shared.

	{ HL1.b : [512 x 1] (gradient)
	  HL1.y : [512 x 1 x *] (gradient)
	  OL.z : [132 x 1 x *] (gradient) }
	{ HL1.W : [512 x 363] (gradient)
	  HL1.z : [512 x 1 x *] }
	{ OL.W : [132 x 512] (gradient)
	  OL.z : [132 x 1 x *] }
	{ HL1.t : [512 x *] (gradient)
	  HL1.y : [512 x 1 x *] }
	{ HL1.z : [512 x 1 x *] (gradient)
	  OL.t : [132 x 1 x *] }


11/24/2016 19:24:12: Training 254084 parameters in 4 out of 4 parameter tensors and 10 nodes with gradient:

11/24/2016 19:24:12: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
11/24/2016 19:24:12: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 19:24:12: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
11/24/2016 19:24:12: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

11/24/2016 19:24:12: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

11/24/2016 19:24:12: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

11/24/2016 19:24:12: Starting minibatch loop.
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.12%]: ce = 3.74183846 * 2560; err = 0.80195313 * 2560; time = 0.1288s; samplesPerSecond = 19869.3
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.91124763 * 2560; err = 0.70898438 * 2560; time = 0.0082s; samplesPerSecond = 312996.7
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.58015976 * 2560; err = 0.66640625 * 2560; time = 0.0081s; samplesPerSecond = 316283.7
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 2.27427139 * 2560; err = 0.58750000 * 2560; time = 0.0080s; samplesPerSecond = 320480.7
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.62%]: ce = 2.05503616 * 2560; err = 0.56093750 * 2560; time = 0.0079s; samplesPerSecond = 322053.1
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.91055145 * 2560; err = 0.52812500 * 2560; time = 0.0079s; samplesPerSecond = 322946.9
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.81562805 * 2560; err = 0.51171875 * 2560; time = 0.0080s; samplesPerSecond = 321608.0
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.68803253 * 2560; err = 0.48476562 * 2560; time = 0.0079s; samplesPerSecond = 323600.1
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.57382050 * 2560; err = 0.45429687 * 2560; time = 0.0079s; samplesPerSecond = 323641.0
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.62090302 * 2560; err = 0.47304687 * 2560; time = 0.0079s; samplesPerSecond = 322093.6
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.59272614 * 2560; err = 0.47500000 * 2560; time = 0.0079s; samplesPerSecond = 324914.3
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.51520233 * 2560; err = 0.44531250 * 2560; time = 0.0079s; samplesPerSecond = 323314.0
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.49181976 * 2560; err = 0.45039062 * 2560; time = 0.0079s; samplesPerSecond = 324379.1
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.53703613 * 2560; err = 0.44804688 * 2560; time = 0.0079s; samplesPerSecond = 324584.8
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.43095093 * 2560; err = 0.41640625 * 2560; time = 0.0080s; samplesPerSecond = 321729.3
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.41503906 * 2560; err = 0.40078125 * 2560; time = 0.0079s; samplesPerSecond = 323681.9
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.38913269 * 2560; err = 0.41132812 * 2560; time = 0.0079s; samplesPerSecond = 323232.3
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.41208191 * 2560; err = 0.42226562 * 2560; time = 0.0079s; samplesPerSecond = 325079.4
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.39966431 * 2560; err = 0.40664062 * 2560; time = 0.0080s; samplesPerSecond = 319960.0
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.42729187 * 2560; err = 0.42617187 * 2560; time = 0.0080s; samplesPerSecond = 320721.6
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.41336365 * 2560; err = 0.42343750 * 2560; time = 0.0079s; samplesPerSecond = 322336.9
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.33192749 * 2560; err = 0.39921875 * 2560; time = 0.0080s; samplesPerSecond = 321164.2
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.28583069 * 2560; err = 0.38671875 * 2560; time = 0.0079s; samplesPerSecond = 322580.6
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.34125366 * 2560; err = 0.40976563 * 2560; time = 0.0080s; samplesPerSecond = 320280.2
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.32662354 * 2560; err = 0.39687500 * 2560; time = 0.0080s; samplesPerSecond = 321527.3
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.21427002 * 2560; err = 0.37187500 * 2560; time = 0.0079s; samplesPerSecond = 323191.5
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.23751526 * 2560; err = 0.37382813 * 2560; time = 0.0080s; samplesPerSecond = 320480.7
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.29967346 * 2560; err = 0.39062500 * 2560; time = 0.0080s; samplesPerSecond = 318645.8
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.21246338 * 2560; err = 0.37382813 * 2560; time = 0.0079s; samplesPerSecond = 323927.6
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.20534058 * 2560; err = 0.36835937 * 2560; time = 0.0079s; samplesPerSecond = 323518.3
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.23593445 * 2560; err = 0.37187500 * 2560; time = 0.0079s; samplesPerSecond = 323559.2
11/24/2016 19:24:12:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.25566101 * 2560; err = 0.38007812 * 2560; time = 0.0078s; samplesPerSecond = 326364.1
11/24/2016 19:24:12: Finished Epoch[ 1 of 2]: [Training] ce = 1.62944660 * 81920; err = 0.46020508 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.478837s
11/24/2016 19:24:12: SGD: Saving checkpoint model '/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech.1'

11/24/2016 19:24:12: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

11/24/2016 19:24:12: Starting minibatch loop.
11/24/2016 19:24:12:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.12%]: ce = 1.23269291 * 2560; err = 0.38164063 * 2560; time = 0.0094s; samplesPerSecond = 272717.6
11/24/2016 19:24:12:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.20291767 * 2560; err = 0.37304688 * 2560; time = 0.0080s; samplesPerSecond = 321043.4
11/24/2016 19:24:12:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.28558159 * 2560; err = 0.37695312 * 2560; time = 0.0079s; samplesPerSecond = 322702.6
11/24/2016 19:24:12:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.22916222 * 2560; err = 0.37421875 * 2560; time = 0.0079s; samplesPerSecond = 322621.3
11/24/2016 19:24:12:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.18205528 * 2560; err = 0.35585937 * 2560; time = 0.0080s; samplesPerSecond = 318051.9
11/24/2016 19:24:12:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.28033676 * 2560; err = 0.37890625 * 2560; time = 0.0079s; samplesPerSecond = 322865.4
11/24/2016 19:24:12:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.22179184 * 2560; err = 0.37421875 * 2560; time = 0.0080s; samplesPerSecond = 321931.6
11/24/2016 19:24:12:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.17912292 * 2560; err = 0.36640625 * 2560; time = 0.0079s; samplesPerSecond = 323150.7
11/24/2016 19:24:12:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.23585739 * 2560; err = 0.35976562 * 2560; time = 0.0079s; samplesPerSecond = 322215.2
11/24/2016 19:24:12:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.18168030 * 2560; err = 0.37460938 * 2560; time = 0.0079s; samplesPerSecond = 322540.0
11/24/2016 19:24:12:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.19452591 * 2560; err = 0.35859375 * 2560; time = 0.0079s; samplesPerSecond = 324667.1
11/24/2016 19:24:12:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.18433685 * 2560; err = 0.34609375 * 2560; time = 0.0080s; samplesPerSecond = 320400.5
11/24/2016 19:24:12:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.16999817 * 2560; err = 0.36562500 * 2560; time = 0.0080s; samplesPerSecond = 318764.8
11/24/2016 19:24:12:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.13339691 * 2560; err = 0.35507813 * 2560; time = 0.0080s; samplesPerSecond = 318328.8
11/24/2016 19:24:12:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.10162354 * 2560; err = 0.32734375 * 2560; time = 0.0080s; samplesPerSecond = 319401.1
11/24/2016 19:24:12:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.10350647 * 2560; err = 0.33593750 * 2560; time = 0.0080s; samplesPerSecond = 319720.2
11/24/2016 19:24:12:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.19208984 * 2560; err = 0.35781250 * 2560; time = 0.0080s; samplesPerSecond = 321244.8
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.16002197 * 2560; err = 0.35468750 * 2560; time = 0.0097s; samplesPerSecond = 264763.7
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.11639099 * 2560; err = 0.34453125 * 2560; time = 0.0089s; samplesPerSecond = 287964.0
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.12366943 * 2560; err = 0.35234375 * 2560; time = 0.0083s; samplesPerSecond = 309889.8
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.09730225 * 2560; err = 0.32656250 * 2560; time = 0.0081s; samplesPerSecond = 314767.0
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.13167572 * 2560; err = 0.34296875 * 2560; time = 0.0081s; samplesPerSecond = 317539.1
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.13528748 * 2560; err = 0.34882812 * 2560; time = 0.0081s; samplesPerSecond = 317657.3
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.29873352 * 2560; err = 0.39023438 * 2560; time = 0.0080s; samplesPerSecond = 318883.9
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.18422852 * 2560; err = 0.35937500 * 2560; time = 0.0080s; samplesPerSecond = 320681.4
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.13612366 * 2560; err = 0.35507813 * 2560; time = 0.0080s; samplesPerSecond = 321406.2
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.14573059 * 2560; err = 0.34843750 * 2560; time = 0.0080s; samplesPerSecond = 321891.1
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.14446716 * 2560; err = 0.34726563 * 2560; time = 0.0078s; samplesPerSecond = 326530.6
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.06778870 * 2560; err = 0.33476563 * 2560; time = 0.0079s; samplesPerSecond = 325244.6
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.09552002 * 2560; err = 0.33398438 * 2560; time = 0.0079s; samplesPerSecond = 322580.6
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.08288879 * 2560; err = 0.33671875 * 2560; time = 0.0078s; samplesPerSecond = 327240.2
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.06622925 * 2560; err = 0.33281250 * 2560; time = 0.0077s; samplesPerSecond = 331262.9
11/24/2016 19:24:13: Finished Epoch[ 2 of 2]: [Training] ce = 1.16552296 * 81920; err = 0.35533447 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.262556s
11/24/2016 19:24:13: SGD: Saving checkpoint model '/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/models/Pre1/cntkSpeech'

11/24/2016 19:24:13: Action "train" complete.


11/24/2016 19:24:13: ##############################################################################
11/24/2016 19:24:13: #                                                                            #
11/24/2016 19:24:13: # addLayer2 command (edit action)                                            #
11/24/2016 19:24:13: #                                                                            #
11/24/2016 19:24:13: ##############################################################################


11/24/2016 19:24:13: Action "edit" complete.


11/24/2016 19:24:13: ##############################################################################
11/24/2016 19:24:13: #                                                                            #
11/24/2016 19:24:13: # dptPre2 command (train action)                                             #
11/24/2016 19:24:13: #                                                                            #
11/24/2016 19:24:13: ##############################################################################

11/24/2016 19:24:13: 
Starting from checkpoint. Loading network from '/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file /tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.scp ... 948 entries
total 132 state names in state list /tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData/state.list
htkmlfreader: reading MLF file /tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
11/24/2016 19:24:13: 
Model has 24 nodes. Using GPU 0.

11/24/2016 19:24:13: Training criterion:   ce = CrossEntropyWithSoftmax
11/24/2016 19:24:13: Evaluation criterion: err = ClassificationError

11/24/2016 19:24:13: Training 516740 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

11/24/2016 19:24:13: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
11/24/2016 19:24:13: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 19:24:13: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
11/24/2016 19:24:13: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 19:24:13: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
11/24/2016 19:24:13: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

11/24/2016 19:24:13: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

11/24/2016 19:24:13: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

11/24/2016 19:24:13: Starting minibatch loop.
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[   1-  10, 3.12%]: ce = 4.39397278 * 2560; err = 0.80781250 * 2560; time = 0.0144s; samplesPerSecond = 177938.4
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[  11-  20, 6.25%]: ce = 2.82511444 * 2560; err = 0.72187500 * 2560; time = 0.0113s; samplesPerSecond = 225809.3
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[  21-  30, 9.38%]: ce = 2.22725906 * 2560; err = 0.57851562 * 2560; time = 0.0113s; samplesPerSecond = 225590.4
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.91397247 * 2560; err = 0.50859375 * 2560; time = 0.0113s; samplesPerSecond = 225829.2
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.71832962 * 2560; err = 0.47812500 * 2560; time = 0.0113s; samplesPerSecond = 226288.3
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.60741425 * 2560; err = 0.45898438 * 2560; time = 0.0113s; samplesPerSecond = 226608.8
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.56547241 * 2560; err = 0.45039062 * 2560; time = 0.0113s; samplesPerSecond = 226008.7
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.47599487 * 2560; err = 0.42773438 * 2560; time = 0.0113s; samplesPerSecond = 225670.0
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.39255371 * 2560; err = 0.40625000 * 2560; time = 0.0113s; samplesPerSecond = 226709.2
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.42025909 * 2560; err = 0.42695312 * 2560; time = 0.0114s; samplesPerSecond = 225292.6
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.40285797 * 2560; err = 0.43203125 * 2560; time = 0.0113s; samplesPerSecond = 226228.3
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.37360992 * 2560; err = 0.41210938 * 2560; time = 0.0114s; samplesPerSecond = 225213.3
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.34541016 * 2560; err = 0.41132812 * 2560; time = 0.0113s; samplesPerSecond = 226568.7
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.40011444 * 2560; err = 0.40625000 * 2560; time = 0.0113s; samplesPerSecond = 225968.8
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.33474121 * 2560; err = 0.39804688 * 2560; time = 0.0114s; samplesPerSecond = 225491.1
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.33484497 * 2560; err = 0.40078125 * 2560; time = 0.0113s; samplesPerSecond = 227010.7
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.26447144 * 2560; err = 0.37500000 * 2560; time = 0.0114s; samplesPerSecond = 224561.4
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.28161011 * 2560; err = 0.39179687 * 2560; time = 0.0113s; samplesPerSecond = 226268.3
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.30275269 * 2560; err = 0.39023438 * 2560; time = 0.0113s; samplesPerSecond = 225968.8
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.28338013 * 2560; err = 0.39648438 * 2560; time = 0.0114s; samplesPerSecond = 225530.8
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.26476746 * 2560; err = 0.39140625 * 2560; time = 0.0114s; samplesPerSecond = 225153.9
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.21593323 * 2560; err = 0.36679688 * 2560; time = 0.0113s; samplesPerSecond = 225789.4
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.21276855 * 2560; err = 0.37187500 * 2560; time = 0.0113s; samplesPerSecond = 226068.5
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.25262756 * 2560; err = 0.37812500 * 2560; time = 0.0113s; samplesPerSecond = 225829.2
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.23072510 * 2560; err = 0.37578125 * 2560; time = 0.0113s; samplesPerSecond = 226048.6
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.15166016 * 2560; err = 0.35351562 * 2560; time = 0.0114s; samplesPerSecond = 225491.1
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.16847839 * 2560; err = 0.35351562 * 2560; time = 0.0113s; samplesPerSecond = 225670.0
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.22899780 * 2560; err = 0.36757812 * 2560; time = 0.0113s; samplesPerSecond = 226168.4
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.16620483 * 2560; err = 0.36093750 * 2560; time = 0.0113s; samplesPerSecond = 225570.5
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.17404785 * 2560; err = 0.35898438 * 2560; time = 0.0114s; samplesPerSecond = 224995.6
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.16364441 * 2560; err = 0.34960938 * 2560; time = 0.0115s; samplesPerSecond = 222106.5
11/24/2016 19:24:13:  Epoch[ 1 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.16885071 * 2560; err = 0.34882812 * 2560; time = 0.0115s; samplesPerSecond = 222125.8
11/24/2016 19:24:13: Finished Epoch[ 1 of 2]: [Training] ce = 1.50821381 * 81920; err = 0.42675781 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.466833s
11/24/2016 19:24:13: SGD: Saving checkpoint model '/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech.1'

11/24/2016 19:24:13: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.900000  momentum as time constant = 2429.8 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

11/24/2016 19:24:13: Starting minibatch loop.
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[   1-  10, 3.12%]: ce = 1.14506922 * 2560; err = 0.35273437 * 2560; time = 0.0125s; samplesPerSecond = 204800.0
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[  11-  20, 6.25%]: ce = 1.17135897 * 2560; err = 0.36289063 * 2560; time = 0.0113s; samplesPerSecond = 226188.4
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[  21-  30, 9.38%]: ce = 1.23678608 * 2560; err = 0.37109375 * 2560; time = 0.0113s; samplesPerSecond = 226128.4
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[  31-  40, 12.50%]: ce = 1.18061256 * 2560; err = 0.36015625 * 2560; time = 0.0114s; samplesPerSecond = 224227.0
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[  41-  50, 15.62%]: ce = 1.13805771 * 2560; err = 0.34648438 * 2560; time = 0.0116s; samplesPerSecond = 221434.1
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[  51-  60, 18.75%]: ce = 1.21805611 * 2560; err = 0.36757812 * 2560; time = 0.0114s; samplesPerSecond = 223874.1
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[  61-  70, 21.88%]: ce = 1.14249344 * 2560; err = 0.34375000 * 2560; time = 0.0114s; samplesPerSecond = 224877.0
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[  71-  80, 25.00%]: ce = 1.12427826 * 2560; err = 0.34726563 * 2560; time = 0.0113s; samplesPerSecond = 225670.0
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[  81-  90, 28.12%]: ce = 1.14438095 * 2560; err = 0.33710937 * 2560; time = 0.0115s; samplesPerSecond = 222183.6
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[  91- 100, 31.25%]: ce = 1.13142624 * 2560; err = 0.35312500 * 2560; time = 0.0114s; samplesPerSecond = 223756.7
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[ 101- 110, 34.38%]: ce = 1.15016861 * 2560; err = 0.34414062 * 2560; time = 0.0114s; samplesPerSecond = 224699.4
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[ 111- 120, 37.50%]: ce = 1.13406601 * 2560; err = 0.34414062 * 2560; time = 0.0114s; samplesPerSecond = 224896.8
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[ 121- 130, 40.62%]: ce = 1.11304169 * 2560; err = 0.34531250 * 2560; time = 0.0113s; samplesPerSecond = 225689.9
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[ 131- 140, 43.75%]: ce = 1.06919556 * 2560; err = 0.32539062 * 2560; time = 0.0113s; samplesPerSecond = 225570.5
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[ 141- 150, 46.88%]: ce = 1.05317383 * 2560; err = 0.31328125 * 2560; time = 0.0113s; samplesPerSecond = 225968.8
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[ 151- 160, 50.00%]: ce = 1.06616211 * 2560; err = 0.33046875 * 2560; time = 0.0114s; samplesPerSecond = 224286.0
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[ 161- 170, 53.12%]: ce = 1.14737701 * 2560; err = 0.35156250 * 2560; time = 0.0114s; samplesPerSecond = 223854.5
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[ 171- 180, 56.25%]: ce = 1.14563141 * 2560; err = 0.35781250 * 2560; time = 0.0113s; samplesPerSecond = 225610.3
11/24/2016 19:24:13:  Epoch[ 2 of 2]-Minibatch[ 181- 190, 59.38%]: ce = 1.08380737 * 2560; err = 0.33515625 * 2560; time = 0.0113s; samplesPerSecond = 225809.3
11/24/2016 19:24:14:  Epoch[ 2 of 2]-Minibatch[ 191- 200, 62.50%]: ce = 1.07361450 * 2560; err = 0.33593750 * 2560; time = 0.0114s; samplesPerSecond = 225233.2
11/24/2016 19:24:14:  Epoch[ 2 of 2]-Minibatch[ 201- 210, 65.62%]: ce = 1.06135559 * 2560; err = 0.32187500 * 2560; time = 0.0114s; samplesPerSecond = 225431.5
11/24/2016 19:24:14:  Epoch[ 2 of 2]-Minibatch[ 211- 220, 68.75%]: ce = 1.09151154 * 2560; err = 0.33085938 * 2560; time = 0.0113s; samplesPerSecond = 225869.1
11/24/2016 19:24:14:  Epoch[ 2 of 2]-Minibatch[ 221- 230, 71.88%]: ce = 1.12316284 * 2560; err = 0.35039063 * 2560; time = 0.0113s; samplesPerSecond = 225769.5
11/24/2016 19:24:14:  Epoch[ 2 of 2]-Minibatch[ 231- 240, 75.00%]: ce = 1.13823547 * 2560; err = 0.35625000 * 2560; time = 0.0113s; samplesPerSecond = 225829.2
11/24/2016 19:24:14:  Epoch[ 2 of 2]-Minibatch[ 241- 250, 78.12%]: ce = 1.09434204 * 2560; err = 0.33750000 * 2560; time = 0.0113s; samplesPerSecond = 225670.0
11/24/2016 19:24:14:  Epoch[ 2 of 2]-Minibatch[ 251- 260, 81.25%]: ce = 1.06899719 * 2560; err = 0.32734375 * 2560; time = 0.0114s; samplesPerSecond = 224817.8
11/24/2016 19:24:14:  Epoch[ 2 of 2]-Minibatch[ 261- 270, 84.38%]: ce = 1.06006470 * 2560; err = 0.31992188 * 2560; time = 0.0115s; samplesPerSecond = 223015.9
11/24/2016 19:24:14:  Epoch[ 2 of 2]-Minibatch[ 271- 280, 87.50%]: ce = 1.10214233 * 2560; err = 0.32929687 * 2560; time = 0.0114s; samplesPerSecond = 225253.0
11/24/2016 19:24:14:  Epoch[ 2 of 2]-Minibatch[ 281- 290, 90.62%]: ce = 1.02476196 * 2560; err = 0.33046875 * 2560; time = 0.0114s; samplesPerSecond = 225332.3
11/24/2016 19:24:14:  Epoch[ 2 of 2]-Minibatch[ 291- 300, 93.75%]: ce = 1.07595520 * 2560; err = 0.33320312 * 2560; time = 0.0114s; samplesPerSecond = 225193.5
11/24/2016 19:24:14:  Epoch[ 2 of 2]-Minibatch[ 301- 310, 96.88%]: ce = 1.06716003 * 2560; err = 0.32968750 * 2560; time = 0.0113s; samplesPerSecond = 225928.9
11/24/2016 19:24:14:  Epoch[ 2 of 2]-Minibatch[ 311- 320, 100.00%]: ce = 1.05657959 * 2560; err = 0.33125000 * 2560; time = 0.0113s; samplesPerSecond = 225709.8
11/24/2016 19:24:14: Finished Epoch[ 2 of 2]: [Training] ce = 1.11353207 * 81920; err = 0.34135742 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.368531s
11/24/2016 19:24:14: SGD: Saving checkpoint model '/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/models/Pre2/cntkSpeech'

11/24/2016 19:24:14: Action "train" complete.


11/24/2016 19:24:14: ##############################################################################
11/24/2016 19:24:14: #                                                                            #
11/24/2016 19:24:14: # addLayer3 command (edit action)                                            #
11/24/2016 19:24:14: #                                                                            #
11/24/2016 19:24:14: ##############################################################################


11/24/2016 19:24:14: Action "edit" complete.


11/24/2016 19:24:14: ##############################################################################
11/24/2016 19:24:14: #                                                                            #
11/24/2016 19:24:14: # speechTrain command (train action)                                         #
11/24/2016 19:24:14: #                                                                            #
11/24/2016 19:24:14: ##############################################################################

11/24/2016 19:24:14: 
Starting from checkpoint. Loading network from '/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.0'.
NDLBuilder Using GPU 0
reading script file /tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.scp ... 948 entries
total 132 state names in state list /tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData/state.list
htkmlfreader: reading MLF file /tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.mlf ... total 948 entries
...............................................................................................feature set 0: 252734 frames in 948 out of 948 utterances
label set 0: 129 classes
minibatchutterancesource: 948 utterances grouped into 3 chunks, av. chunk size: 316.0 utterances, 84244.7 frames
11/24/2016 19:24:14: 
Model has 29 nodes. Using GPU 0.

11/24/2016 19:24:14: Training criterion:   ce = CrossEntropyWithSoftmax
11/24/2016 19:24:14: Evaluation criterion: err = ClassificationError

11/24/2016 19:24:14: Training 779396 parameters in 8 out of 8 parameter tensors and 20 nodes with gradient:

11/24/2016 19:24:14: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
11/24/2016 19:24:14: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 19:24:14: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
11/24/2016 19:24:14: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 19:24:14: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
11/24/2016 19:24:14: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 19:24:14: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
11/24/2016 19:24:14: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

11/24/2016 19:24:14: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

11/24/2016 19:24:14: Starting Epoch 1: learning rate per sample = 0.003125  effective momentum = 0.900117  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

11/24/2016 19:24:14: Starting minibatch loop.
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[   1-  10, 3.12%]: ce = 3.98265686 * 2560; err = 0.81054688 * 2560; time = 0.0190s; samplesPerSecond = 134524.4
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[  11-  20, 6.25%]: ce = 2.64980240 * 2560; err = 0.63398438 * 2560; time = 0.0155s; samplesPerSecond = 164842.2
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[  21-  30, 9.38%]: ce = 2.03017731 * 2560; err = 0.54414063 * 2560; time = 0.0154s; samplesPerSecond = 165985.9
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[  31-  40, 12.50%]: ce = 1.74546738 * 2560; err = 0.47460938 * 2560; time = 0.0154s; samplesPerSecond = 166028.9
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[  41-  50, 15.62%]: ce = 1.57823792 * 2560; err = 0.44843750 * 2560; time = 0.0154s; samplesPerSecond = 165975.1
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[  51-  60, 18.75%]: ce = 1.47351074 * 2560; err = 0.41445312 * 2560; time = 0.0155s; samplesPerSecond = 165513.7
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[  61-  70, 21.88%]: ce = 1.43362732 * 2560; err = 0.40859375 * 2560; time = 0.0154s; samplesPerSecond = 166050.5
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[  71-  80, 25.00%]: ce = 1.36078033 * 2560; err = 0.39570312 * 2560; time = 0.0156s; samplesPerSecond = 163724.7
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[  81-  90, 28.12%]: ce = 1.28377380 * 2560; err = 0.38085938 * 2560; time = 0.0155s; samplesPerSecond = 165385.4
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[  91- 100, 31.25%]: ce = 1.29924469 * 2560; err = 0.39765625 * 2560; time = 0.0155s; samplesPerSecond = 165235.9
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[ 101- 110, 34.38%]: ce = 1.28587341 * 2560; err = 0.39062500 * 2560; time = 0.0156s; samplesPerSecond = 164176.2
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[ 111- 120, 37.50%]: ce = 1.27888489 * 2560; err = 0.38320312 * 2560; time = 0.0155s; samplesPerSecond = 165118.7
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[ 121- 130, 40.62%]: ce = 1.23967896 * 2560; err = 0.37539062 * 2560; time = 0.0154s; samplesPerSecond = 165749.4
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[ 131- 140, 43.75%]: ce = 1.31078186 * 2560; err = 0.38984375 * 2560; time = 0.0155s; samplesPerSecond = 165321.3
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[ 141- 150, 46.88%]: ce = 1.25354767 * 2560; err = 0.36796875 * 2560; time = 0.0157s; samplesPerSecond = 163130.1
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[ 151- 160, 50.00%]: ce = 1.26726074 * 2560; err = 0.38242188 * 2560; time = 0.0155s; samplesPerSecond = 165182.6
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[ 161- 170, 53.12%]: ce = 1.20307617 * 2560; err = 0.36328125 * 2560; time = 0.0155s; samplesPerSecond = 165225.2
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[ 171- 180, 56.25%]: ce = 1.20711365 * 2560; err = 0.36484375 * 2560; time = 0.0155s; samplesPerSecond = 165481.6
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[ 181- 190, 59.38%]: ce = 1.20856934 * 2560; err = 0.37070313 * 2560; time = 0.0155s; samplesPerSecond = 165545.8
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[ 191- 200, 62.50%]: ce = 1.20545654 * 2560; err = 0.37578125 * 2560; time = 0.0155s; samplesPerSecond = 165310.6
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[ 201- 210, 65.62%]: ce = 1.20523376 * 2560; err = 0.37265625 * 2560; time = 0.0155s; samplesPerSecond = 164874.1
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[ 211- 220, 68.75%]: ce = 1.14180908 * 2560; err = 0.34414062 * 2560; time = 0.0154s; samplesPerSecond = 165932.1
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[ 221- 230, 71.88%]: ce = 1.14962158 * 2560; err = 0.35078125 * 2560; time = 0.0155s; samplesPerSecond = 165492.3
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[ 231- 240, 75.00%]: ce = 1.19320374 * 2560; err = 0.35898438 * 2560; time = 0.0155s; samplesPerSecond = 165631.5
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[ 241- 250, 78.12%]: ce = 1.17249146 * 2560; err = 0.36445312 * 2560; time = 0.0155s; samplesPerSecond = 165695.8
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[ 251- 260, 81.25%]: ce = 1.08261414 * 2560; err = 0.33945313 * 2560; time = 0.0155s; samplesPerSecond = 165374.7
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[ 261- 270, 84.38%]: ce = 1.11113586 * 2560; err = 0.34375000 * 2560; time = 0.0159s; samplesPerSecond = 160733.3
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[ 271- 280, 87.50%]: ce = 1.17623291 * 2560; err = 0.35156250 * 2560; time = 0.0156s; samplesPerSecond = 163620.1
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[ 281- 290, 90.62%]: ce = 1.11094666 * 2560; err = 0.34804687 * 2560; time = 0.0156s; samplesPerSecond = 164408.2
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[ 291- 300, 93.75%]: ce = 1.12750549 * 2560; err = 0.34062500 * 2560; time = 0.0156s; samplesPerSecond = 164228.9
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[ 301- 310, 96.88%]: ce = 1.12247925 * 2560; err = 0.34492187 * 2560; time = 0.0155s; samplesPerSecond = 164704.4
11/24/2016 19:24:14:  Epoch[ 1 of 4]-Minibatch[ 311- 320, 100.00%]: ce = 1.12257080 * 2560; err = 0.34335938 * 2560; time = 0.0156s; samplesPerSecond = 164323.8
11/24/2016 19:24:14: Finished Epoch[ 1 of 4]: [Training] ce = 1.40666771 * 81920; err = 0.40236816 * 81920; totalSamplesSeen = 81920; learningRatePerSample = 0.003125; epochTime=0.599425s
11/24/2016 19:24:14: SGD: Saving checkpoint model '/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.1'

11/24/2016 19:24:15: Starting Epoch 2: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 81920), data subset 0 of 1, with 1 datapasses

11/24/2016 19:24:15: Starting minibatch loop.
11/24/2016 19:24:15:  Epoch[ 2 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.52495832 * 5120; err = 0.42050781 * 5120; time = 0.0280s; samplesPerSecond = 183059.8
11/24/2016 19:24:15:  Epoch[ 2 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.54641657 * 5120; err = 0.42519531 * 5120; time = 0.0243s; samplesPerSecond = 210977.4
11/24/2016 19:24:15:  Epoch[ 2 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.22311935 * 5120; err = 0.37011719 * 5120; time = 0.0242s; samplesPerSecond = 211369.4
11/24/2016 19:24:15:  Epoch[ 2 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.12978401 * 5120; err = 0.34003906 * 5120; time = 0.0241s; samplesPerSecond = 212210.4
11/24/2016 19:24:15:  Epoch[ 2 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.11905899 * 5120; err = 0.33906250 * 5120; time = 0.0241s; samplesPerSecond = 212757.1
11/24/2016 19:24:15:  Epoch[ 2 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.13513794 * 5120; err = 0.34550781 * 5120; time = 0.0242s; samplesPerSecond = 211938.1
11/24/2016 19:24:15:  Epoch[ 2 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.08784714 * 5120; err = 0.33632812 * 5120; time = 0.0241s; samplesPerSecond = 212280.8
11/24/2016 19:24:15:  Epoch[ 2 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.07431335 * 5120; err = 0.33046875 * 5120; time = 0.0241s; samplesPerSecond = 212368.8
11/24/2016 19:24:15:  Epoch[ 2 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.15605774 * 5120; err = 0.35742188 * 5120; time = 0.0241s; samplesPerSecond = 212254.4
11/24/2016 19:24:15:  Epoch[ 2 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.06616287 * 5120; err = 0.33496094 * 5120; time = 0.0241s; samplesPerSecond = 212439.3
11/24/2016 19:24:15:  Epoch[ 2 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.05716934 * 5120; err = 0.32910156 * 5120; time = 0.0241s; samplesPerSecond = 212360.0
11/24/2016 19:24:15:  Epoch[ 2 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.13308563 * 5120; err = 0.35664062 * 5120; time = 0.0241s; samplesPerSecond = 212210.4
11/24/2016 19:24:15:  Epoch[ 2 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.11535950 * 5120; err = 0.34785156 * 5120; time = 0.0241s; samplesPerSecond = 212430.5
11/24/2016 19:24:15:  Epoch[ 2 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.09246063 * 5120; err = 0.32890625 * 5120; time = 0.0241s; samplesPerSecond = 212448.1
11/24/2016 19:24:15:  Epoch[ 2 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.04727173 * 5120; err = 0.32929687 * 5120; time = 0.0242s; samplesPerSecond = 211911.8
11/24/2016 19:24:15:  Epoch[ 2 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.06195679 * 5120; err = 0.32578125 * 5120; time = 0.0241s; samplesPerSecond = 212562.8
11/24/2016 19:24:15: Finished Epoch[ 2 of 4]: [Training] ce = 1.16063499 * 81920; err = 0.35107422 * 81920; totalSamplesSeen = 163840; learningRatePerSample = 0.003125; epochTime=0.393658s
11/24/2016 19:24:15: SGD: Saving checkpoint model '/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.2'

11/24/2016 19:24:15: Starting Epoch 3: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 163840), data subset 0 of 1, with 1 datapasses

11/24/2016 19:24:15: Starting minibatch loop.
11/24/2016 19:24:15:  Epoch[ 3 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.11231699 * 5120; err = 0.33750000 * 5120; time = 0.0249s; samplesPerSecond = 205408.0
11/24/2016 19:24:15:  Epoch[ 3 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.10804968 * 5120; err = 0.34843750 * 5120; time = 0.0241s; samplesPerSecond = 212034.6
11/24/2016 19:24:15:  Epoch[ 3 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.09022064 * 5120; err = 0.34726563 * 5120; time = 0.0241s; samplesPerSecond = 212175.2
11/24/2016 19:24:15:  Epoch[ 3 of 4]-Minibatch[  31-  40, 25.00%]: ce = 1.08266754 * 5120; err = 0.32539062 * 5120; time = 0.0241s; samplesPerSecond = 212757.1
11/24/2016 19:24:15:  Epoch[ 3 of 4]-Minibatch[  41-  50, 31.25%]: ce = 1.11265411 * 5120; err = 0.33808594 * 5120; time = 0.0242s; samplesPerSecond = 211955.6
11/24/2016 19:24:15:  Epoch[ 3 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.07451935 * 5120; err = 0.33007812 * 5120; time = 0.0241s; samplesPerSecond = 212113.7
11/24/2016 19:24:15:  Epoch[ 3 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.08691254 * 5120; err = 0.33867188 * 5120; time = 0.0242s; samplesPerSecond = 211666.5
11/24/2016 19:24:15:  Epoch[ 3 of 4]-Minibatch[  71-  80, 50.00%]: ce = 1.08186264 * 5120; err = 0.33203125 * 5120; time = 0.0241s; samplesPerSecond = 212642.2
11/24/2016 19:24:15:  Epoch[ 3 of 4]-Minibatch[  81-  90, 56.25%]: ce = 1.02816010 * 5120; err = 0.31582031 * 5120; time = 0.0241s; samplesPerSecond = 212360.0
11/24/2016 19:24:15:  Epoch[ 3 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.04833908 * 5120; err = 0.32148437 * 5120; time = 0.0241s; samplesPerSecond = 212562.8
11/24/2016 19:24:15:  Epoch[ 3 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.05743637 * 5120; err = 0.33515625 * 5120; time = 0.0241s; samplesPerSecond = 212615.8
11/24/2016 19:24:15:  Epoch[ 3 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.08609924 * 5120; err = 0.34160156 * 5120; time = 0.0241s; samplesPerSecond = 212245.6
11/24/2016 19:24:15:  Epoch[ 3 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 1.05357971 * 5120; err = 0.31914063 * 5120; time = 0.0241s; samplesPerSecond = 212766.0
11/24/2016 19:24:15:  Epoch[ 3 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 1.01892242 * 5120; err = 0.31972656 * 5120; time = 0.0241s; samplesPerSecond = 212492.2
11/24/2016 19:24:15:  Epoch[ 3 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 1.04624634 * 5120; err = 0.32773438 * 5120; time = 0.0241s; samplesPerSecond = 212774.8
11/24/2016 19:24:15:  Epoch[ 3 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 1.02311554 * 5120; err = 0.31894531 * 5120; time = 0.0241s; samplesPerSecond = 212254.4
11/24/2016 19:24:15: Finished Epoch[ 3 of 4]: [Training] ce = 1.06944389 * 81920; err = 0.33106689 * 81920; totalSamplesSeen = 245760; learningRatePerSample = 0.003125; epochTime=0.389865s
11/24/2016 19:24:15: SGD: Saving checkpoint model '/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.3'

11/24/2016 19:24:15: Starting Epoch 4: learning rate per sample = 0.003125  effective momentum = 0.810210  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 3: frames [245760..327680] (first utterance at frame 245760), data subset 0 of 1, with 1 datapasses

11/24/2016 19:24:15: Starting minibatch loop.
11/24/2016 19:24:15:  Epoch[ 4 of 4]-Minibatch[   1-  10, 6.25%]: ce = 1.02844849 * 5120; err = 0.31621094 * 5120; time = 0.0249s; samplesPerSecond = 205358.6
11/24/2016 19:24:16:  Epoch[ 4 of 4]-Minibatch[  11-  20, 12.50%]: ce = 1.05641066 * 4926; err = 0.33130329 * 4926; time = 0.0658s; samplesPerSecond = 74837.1
11/24/2016 19:24:16:  Epoch[ 4 of 4]-Minibatch[  21-  30, 18.75%]: ce = 1.02023335 * 5120; err = 0.32343750 * 5120; time = 0.0241s; samplesPerSecond = 212236.8
11/24/2016 19:24:16:  Epoch[ 4 of 4]-Minibatch[  31-  40, 25.00%]: ce = 0.99176388 * 5120; err = 0.31269531 * 5120; time = 0.0241s; samplesPerSecond = 212766.0
11/24/2016 19:24:16:  Epoch[ 4 of 4]-Minibatch[  41-  50, 31.25%]: ce = 0.99810143 * 5120; err = 0.31210938 * 5120; time = 0.0241s; samplesPerSecond = 212757.1
11/24/2016 19:24:16:  Epoch[ 4 of 4]-Minibatch[  51-  60, 37.50%]: ce = 1.00280685 * 5120; err = 0.32207031 * 5120; time = 0.0241s; samplesPerSecond = 212157.6
11/24/2016 19:24:16:  Epoch[ 4 of 4]-Minibatch[  61-  70, 43.75%]: ce = 1.02889595 * 5120; err = 0.32246094 * 5120; time = 0.0241s; samplesPerSecond = 212307.2
11/24/2016 19:24:16:  Epoch[ 4 of 4]-Minibatch[  71-  80, 50.00%]: ce = 0.99928970 * 5120; err = 0.31171875 * 5120; time = 0.0242s; samplesPerSecond = 211719.0
11/24/2016 19:24:16:  Epoch[ 4 of 4]-Minibatch[  81-  90, 56.25%]: ce = 0.99335556 * 5120; err = 0.30664062 * 5120; time = 0.0242s; samplesPerSecond = 211929.3
11/24/2016 19:24:16:  Epoch[ 4 of 4]-Minibatch[  91- 100, 62.50%]: ce = 1.00106583 * 5120; err = 0.30996094 * 5120; time = 0.0241s; samplesPerSecond = 212113.7
11/24/2016 19:24:16:  Epoch[ 4 of 4]-Minibatch[ 101- 110, 68.75%]: ce = 1.01961670 * 5120; err = 0.31601563 * 5120; time = 0.0241s; samplesPerSecond = 212580.4
11/24/2016 19:24:16:  Epoch[ 4 of 4]-Minibatch[ 111- 120, 75.00%]: ce = 1.04032364 * 5120; err = 0.32480469 * 5120; time = 0.0241s; samplesPerSecond = 212845.6
11/24/2016 19:24:16:  Epoch[ 4 of 4]-Minibatch[ 121- 130, 81.25%]: ce = 0.97818832 * 5120; err = 0.29960938 * 5120; time = 0.0241s; samplesPerSecond = 212272.0
11/24/2016 19:24:16:  Epoch[ 4 of 4]-Minibatch[ 131- 140, 87.50%]: ce = 0.96928406 * 5120; err = 0.30058594 * 5120; time = 0.0241s; samplesPerSecond = 212043.4
11/24/2016 19:24:16:  Epoch[ 4 of 4]-Minibatch[ 141- 150, 93.75%]: ce = 0.98244171 * 5120; err = 0.31054688 * 5120; time = 0.0241s; samplesPerSecond = 212801.3
11/24/2016 19:24:16:  Epoch[ 4 of 4]-Minibatch[ 151- 160, 100.00%]: ce = 0.97457886 * 5120; err = 0.29785156 * 5120; time = 0.0240s; samplesPerSecond = 212925.2
11/24/2016 19:24:16: Finished Epoch[ 4 of 4]: [Training] ce = 1.00510321 * 81920; err = 0.31368408 * 81920; totalSamplesSeen = 327680; learningRatePerSample = 0.003125; epochTime=0.433126s
11/24/2016 19:24:16: SGD: Saving checkpoint model '/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech'

11/24/2016 19:24:16: Action "train" complete.


11/24/2016 19:24:16: ##############################################################################
11/24/2016 19:24:16: #                                                                            #
11/24/2016 19:24:16: # replaceCriterionNode command (edit action)                                 #
11/24/2016 19:24:16: #                                                                            #
11/24/2016 19:24:16: ##############################################################################


11/24/2016 19:24:16: Action "edit" complete.


11/24/2016 19:24:16: ##############################################################################
11/24/2016 19:24:16: #                                                                            #
11/24/2016 19:24:16: # sequenceTrain command (train action)                                       #
11/24/2016 19:24:16: #                                                                            #
11/24/2016 19:24:16: ##############################################################################

11/24/2016 19:24:16: 
Starting from checkpoint. Loading network from '/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.0'.
NDLBuilder Using GPU 0
simplesenonehmm: reading '/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData/model.overalltying', '/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData/state.list', '/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData/model.transprob'
simplesenonehmm: 83253 units with 45 unique HMMs, 132 tied states, and 45 trans matrices read
reading script file /tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.scp ... 948 entries
trainlayer: OOV-exclusion code enabled, but no unigram specified to derive the word set from, so you won't get OOV exclusion
total 132 state names in state list /tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData/state.list
htkmlfreader: reading MLF file /tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData/glob_0000.mlf ... total 948 entries
archive: opening 80 lattice-archive TOC files ('/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/TestData/CY2SCH010061231_1369712653.numden.lats.toc' etc.).................................................................................. 923 total lattices referenced in 80 archive files
. [no lattice for An4/454/454/an70-meht-b]....... [no lattice for An4/89/89/an6-fjmd-b].. [no lattice for An4/683/683/an364-mmkw-b].. [no lattice for An4/476/476/an256-mewl-b].... [no lattice for An4/2/2/an253-fash-b]...............................................................................feature set 0: 250814 frames in 923 out of 948 utterances
minibatchutterancesource: out of 948 files, 0 files not found in label set and 25 have no lattice
label set 0: 129 classes
minibatchutterancesource: 923 utterances grouped into 3 chunks, av. chunk size: 307.7 utterances, 83604.7 frames
11/24/2016 19:24:16: 
Model has 29 nodes. Using GPU 0.

11/24/2016 19:24:16: Training criterion:   ce = SequenceWithSoftmax
11/24/2016 19:24:16: Evaluation criterion: err = ClassificationError

11/24/2016 19:24:16: Training 779396 parameters in 8 out of 8 parameter tensors and 21 nodes with gradient:

11/24/2016 19:24:16: 	Node 'HL1.W' (LearnableParameter operation) : [512 x 363]
11/24/2016 19:24:16: 	Node 'HL1.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 19:24:16: 	Node 'HL2.W' (LearnableParameter operation) : [512 x 512]
11/24/2016 19:24:16: 	Node 'HL2.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 19:24:16: 	Node 'HL3.W' (LearnableParameter operation) : [512 x 512]
11/24/2016 19:24:16: 	Node 'HL3.b' (LearnableParameter operation) : [512 x 1]
11/24/2016 19:24:16: 	Node 'OL.W' (LearnableParameter operation) : [132 x 512]
11/24/2016 19:24:16: 	Node 'OL.b' (LearnableParameter operation) : [132 x 1]

11/24/2016 19:24:16: No PreCompute nodes found, or all already computed. Skipping pre-computation step.
Setting Hsmoothing weight to 0.95 and frame-dropping threshhold to 1e-10
Setting SeqGammar-related parameters: amf=14.00, lmf=14.00, wp=0.00, bMMIFactor=0.00, usesMBR=false

11/24/2016 19:24:16: Starting Epoch 1: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 0: frames [0..81920] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms

11/24/2016 19:24:20: Starting minibatch loop.
dengamma value 1.001067
dengamma value 1.080157
dengamma value 1.019519
dengamma value 1.062550
dengamma value 1.039983
dengamma value 1.067168
dengamma value 1.015829
dengamma value 1.014958
dengamma value 1.129815
dengamma value 0.953121
dengamma value 1.001604
dengamma value 1.048848
dengamma value 1.041445
dengamma value 1.071283
dengamma value 1.024753
dengamma value 1.075288
dengamma value 1.059411
dengamma value 1.070090
dengamma value 0.993640
dengamma value 1.031318
dengamma value 1.043755
dengamma value 1.073213
11/24/2016 19:24:22:  Epoch[ 1 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08728820 * 5566; err = 0.32411067 * 5566; time = 1.3725s; samplesPerSecond = 4055.3
dengamma value 0.996242
dengamma value 1.038819
dengamma value 1.027608
dengamma value 1.010380
dengamma value 1.014790
dengamma value 1.045738
dengamma value 1.110722
dengamma value 1.038780
dengamma value 1.025774
dengamma value 0.993012
dengamma value 0.993648
dengamma value 1.061104
dengamma value 1.027607
dengamma value 0.999460
dengamma value 1.036514
dengamma value 0.983204
dengamma value 1.003434
dengamma value 1.042607
dengamma value 1.024696
dengamma value 1.084303
dengamma value 1.029496
dengamma value 1.071689
dengamma value 1.037267
dengamma value 1.191192
dengamma value 1.054590
dengamma value 1.052774
11/24/2016 19:24:22:  Epoch[ 1 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.08035404 * 7398; err = 0.31413896 * 7398; time = 0.5951s; samplesPerSecond = 12432.5
dengamma value 1.108737
dengamma value 0.995697
dengamma value 1.030601
dengamma value 0.980079
dengamma value 1.040895
dengamma value 1.060961
dengamma value 1.070254
dengamma value 1.062911
dengamma value 1.090351
dengamma value 1.090454
dengamma value 1.013430
dengamma value 1.068115
dengamma value 1.053355
dengamma value 0.935324
dengamma value 1.096063
dengamma value 1.031839
dengamma value 1.105325
dengamma value 1.007837
dengamma value 1.024426
dengamma value 1.050393
dengamma value 1.046333
dengamma value 1.043673
dengamma value 1.045320
dengamma value 1.100024
dengamma value 1.092750
11/24/2016 19:24:23:  Epoch[ 1 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.07849883 * 6300; err = 0.34031746 * 6300; time = 0.4989s; samplesPerSecond = 12626.8
dengamma value 1.088808
dengamma value 1.183811
dengamma value 1.063196
dengamma value 1.046023
dengamma value 1.040785
dengamma value 0.987674
dengamma value 0.998533
dengamma value 1.047166
dengamma value 1.105286
dengamma value 1.035654
dengamma value 1.033787
dengamma value 1.064993
dengamma value 1.079161
dengamma value 1.041030
dengamma value 1.097539
dengamma value 1.040048
dengamma value 0.999721
dengamma value 1.034257
dengamma value 1.015447
dengamma value 0.980989
dengamma value 0.924786
dengamma value 1.044859
11/24/2016 19:24:23:  Epoch[ 1 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08044421 * 5636; err = 0.32398864 * 5636; time = 0.4397s; samplesPerSecond = 12818.2
dengamma value 1.034473
dengamma value 1.028718
dengamma value 1.039579
dengamma value 1.061096
dengamma value 1.052193
dengamma value 1.074368
dengamma value 1.056228
dengamma value 1.031840
dengamma value 0.944285
dengamma value 1.034448
dengamma value 1.018251
dengamma value 1.055865
dengamma value 1.041591
dengamma value 0.952801
dengamma value 1.052865
dengamma value 0.980702
dengamma value 1.085583
dengamma value 1.011438
dengamma value 1.054262
dengamma value 0.965932
11/24/2016 19:24:24:  Epoch[ 1 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.08190312 * 6970; err = 0.34304161 * 6970; time = 0.5509s; samplesPerSecond = 12652.6
dengamma value 1.057523
dengamma value 1.037841
dengamma value 1.057887
dengamma value 1.036734
dengamma value 1.055027
dengamma value 1.064485
dengamma value 1.044755
dengamma value 1.068413
dengamma value 1.053904
dengamma value 1.042844
dengamma value 1.010017
dengamma value 1.061912
dengamma value 1.027196
dengamma value 1.058909
dengamma value 1.008905
dengamma value 1.074882
dengamma value 1.050775
dengamma value 0.996659
dengamma value 1.120642
dengamma value 1.001781
dengamma value 1.003269
dengamma value 1.055767
11/24/2016 19:24:24:  Epoch[ 1 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08046273 * 6996; err = 0.31932533 * 6996; time = 0.5798s; samplesPerSecond = 12065.8
dengamma value 1.074767
dengamma value 1.021204
dengamma value 1.049758
dengamma value 1.043823
dengamma value 0.996199
dengamma value 1.001958
dengamma value 1.029199
dengamma value 0.973166
dengamma value 1.116241
dengamma value 0.997741
dengamma value 1.040374
dengamma value 1.000890
dengamma value 1.077596
dengamma value 1.073013
dengamma value 1.090024
dengamma value 0.970951
dengamma value 0.990173
dengamma value 1.039257
dengamma value 1.029184
dengamma value 1.123377
dengamma value 1.026184
dengamma value 1.063601
dengamma value 1.081612
dengamma value 1.020579
dengamma value 1.014357
11/24/2016 19:24:25:  Epoch[ 1 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.08633239 * 6180; err = 0.33268608 * 6180; time = 0.5058s; samplesPerSecond = 12217.1
dengamma value 1.035052
dengamma value 1.055853
dengamma value 1.131026
dengamma value 1.003569
dengamma value 1.072652
dengamma value 1.033863
dengamma value 0.989076
dengamma value 1.064374
dengamma value 1.027989
dengamma value 1.047838
dengamma value 1.030231
dengamma value 1.037395
dengamma value 1.088592
dengamma value 0.965899
dengamma value 1.106665
dengamma value 1.041253
dengamma value 1.038023
dengamma value 1.100284
dengamma value 1.050025
dengamma value 1.125211
11/24/2016 19:24:25:  Epoch[ 1 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.08468188 * 4860; err = 0.33312757 * 4860; time = 0.3885s; samplesPerSecond = 12508.8
dengamma value 1.024220
dengamma value 0.963070
dengamma value 1.022284
dengamma value 1.057816
dengamma value 1.027383
dengamma value 1.084353
dengamma value 0.998436
dengamma value 1.072171
dengamma value 1.014029
dengamma value 0.987455
dengamma value 1.034096
dengamma value 0.947688
dengamma value 1.018000
dengamma value 1.072329
dengamma value 1.039579
dengamma value 1.084295
dengamma value 1.057573
dengamma value 1.035422
dengamma value 1.036583
dengamma value 1.000910
dengamma value 1.099041
dengamma value 1.061122
11/24/2016 19:24:26:  Epoch[ 1 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.07716693 * 6046; err = 0.32798544 * 6046; time = 0.4930s; samplesPerSecond = 12263.0
dengamma value 1.036951
dengamma value 1.003620
dengamma value 1.006124
dengamma value 0.958804
dengamma value 1.018693
dengamma value 1.095991
dengamma value 1.037507
dengamma value 0.990920
dengamma value 1.028393
dengamma value 1.053860
dengamma value 0.989630
dengamma value 1.021158
dengamma value 1.048082
dengamma value 1.077865
dengamma value 0.992846
dengamma value 1.054860
dengamma value 1.004839
dengamma value 1.009091
dengamma value 0.994613
dengamma value 0.998620
dengamma value 0.995332
dengamma value 1.066944
dengamma value 1.023445
dengamma value 1.029751
11/24/2016 19:24:26:  Epoch[ 1 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.08725246 * 6942; err = 0.33707865 * 6942; time = 0.5354s; samplesPerSecond = 12965.0
dengamma value 1.011441
dengamma value 1.037689
dengamma value 0.994885
dengamma value 0.935396
dengamma value 1.060894
dengamma value 1.081985
dengamma value 1.134902
dengamma value 1.009710
dengamma value 1.023351
dengamma value 1.109485
dengamma value 1.061709
dengamma value 1.004689
dengamma value 1.067180
dengamma value 1.031659
dengamma value 1.097955
dengamma value 1.010382
dengamma value 1.035297
dengamma value 1.058209
dengamma value 1.013107
dengamma value 0.997639
dengamma value 0.978757
dengamma value 1.052807
dengamma value 1.060015
11/24/2016 19:24:27:  Epoch[ 1 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08840854 * 5784; err = 0.32780083 * 5784; time = 0.4446s; samplesPerSecond = 13009.7
dengamma value 1.077897
dengamma value 1.078268
dengamma value 1.006217
dengamma value 1.009654
dengamma value 1.118175
dengamma value 0.993057
dengamma value 0.963813
dengamma value 0.955830
dengamma value 0.940279
dengamma value 1.031962
dengamma value 1.028442
dengamma value 0.984018
dengamma value 1.061422
dengamma value 1.027417
dengamma value 1.069130
dengamma value 0.985377
dengamma value 1.020775
dengamma value 1.038766
dengamma value 1.068386
dengamma value 0.986619
dengamma value 1.089043
11/24/2016 19:24:27:  Epoch[ 1 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.08892063 * 6258; err = 0.33972515 * 6258; time = 0.4891s; samplesPerSecond = 12795.5
dengamma value 1.094896
dengamma value 1.091116
dengamma value 1.061463
dengamma value 1.071133
dengamma value 1.016828
dengamma value 1.111166
dengamma value 1.068230
dengamma value 1.010327
dengamma value 1.038096
dengamma value 1.020235
dengamma value 1.024535
dengamma value 1.055434
dengamma value 1.048088
dengamma value 1.073387
dengamma value 0.968437
dengamma value 1.001970
dengamma value 1.074712
dengamma value 1.011197
dengamma value 1.094215
dengamma value 0.992759
dengamma value 1.025109
dengamma value 0.960496
11/24/2016 19:24:28:  Epoch[ 1 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08357976 * 6116; err = 0.32226946 * 6116; time = 0.4909s; samplesPerSecond = 12459.3
dengamma value 1.036054
dengamma value 1.051657
dengamma value 0.995793
dengamma value 1.051689
11/24/2016 19:24:28: Finished Epoch[ 1 of 3]: [Training] ce = 0.08357469 * 82574; err = 0.32920774 * 82574; totalSamplesSeen = 82574; learningRatePerSample = 2e-06; epochTime=11.7008s
11/24/2016 19:24:28: SGD: Saving checkpoint model '/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.1'

11/24/2016 19:24:28: Starting Epoch 2: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 1: frames [81920..163840] (first utterance at frame 82146), data subset 0 of 1, with 1 datapasses

11/24/2016 19:24:28: Starting minibatch loop.
dengamma value 1.016223
dengamma value 1.002652
dengamma value 0.981605
dengamma value 1.067915
dengamma value 1.064984
dengamma value 1.001766
dengamma value 1.061643
dengamma value 1.007925
dengamma value 1.026279
dengamma value 1.026566
dengamma value 1.038292
dengamma value 1.003548
dengamma value 1.046595
dengamma value 1.091557
dengamma value 0.961199
dengamma value 0.990602
dengamma value 1.022511
dengamma value 1.016636
dengamma value 1.062380
dengamma value 1.042556
dengamma value 1.060125
dengamma value 1.080020
11/24/2016 19:24:28:  Epoch[ 2 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08417415 * 5826; err = 0.34140062 * 5826; time = 0.4793s; samplesPerSecond = 12155.5
dengamma value 1.058698
dengamma value 1.097357
dengamma value 1.087208
dengamma value 1.041382
dengamma value 1.045358
dengamma value 1.003941
dengamma value 1.082558
dengamma value 1.082099
dengamma value 1.092521
dengamma value 1.041313
dengamma value 1.033947
dengamma value 0.950830
dengamma value 1.075499
dengamma value 1.080184
dengamma value 1.033289
dengamma value 1.043421
dengamma value 1.037847
dengamma value 1.017983
dengamma value 1.040474
dengamma value 1.012613
11/24/2016 19:24:29:  Epoch[ 2 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.08034324 * 6380; err = 0.31536050 * 6380; time = 0.5363s; samplesPerSecond = 11896.8
dengamma value 1.092565
dengamma value 1.024275
dengamma value 1.116525
dengamma value 0.943509
dengamma value 1.032427
dengamma value 1.078101
dengamma value 1.105218
dengamma value 1.037218
dengamma value 1.073576
dengamma value 1.020706
dengamma value 0.988218
dengamma value 1.080714
dengamma value 1.022939
dengamma value 1.052989
dengamma value 1.013656
dengamma value 1.018811
dengamma value 1.054636
dengamma value 1.082024
dengamma value 1.035637
dengamma value 1.037595
dengamma value 1.083356
dengamma value 1.065776
dengamma value 0.993740
11/24/2016 19:24:30:  Epoch[ 2 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.07833749 * 6574; err = 0.31700639 * 6574; time = 0.5754s; samplesPerSecond = 11425.5
dengamma value 1.077104
dengamma value 1.044894
dengamma value 1.054161
dengamma value 1.045469
dengamma value 0.927012
dengamma value 0.961078
dengamma value 1.130222
dengamma value 1.077952
dengamma value 1.020356
dengamma value 1.029394
dengamma value 1.051983
dengamma value 0.966779
dengamma value 1.053841
dengamma value 1.012364
dengamma value 0.961997
dengamma value 1.077806
dengamma value 1.065058
dengamma value 1.094705
dengamma value 0.986651
dengamma value 0.979273
dengamma value 1.074024
dengamma value 1.121549
dengamma value 0.998119
11/24/2016 19:24:30:  Epoch[ 2 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08791709 * 6324; err = 0.33649589 * 6324; time = 0.4969s; samplesPerSecond = 12726.4
dengamma value 0.955998
dengamma value 0.935337
dengamma value 0.939079
dengamma value 1.050439
dengamma value 1.078258
dengamma value 1.101086
dengamma value 1.032791
dengamma value 1.146370
dengamma value 1.027905
dengamma value 0.981313
dengamma value 1.011069
dengamma value 1.014181
dengamma value 0.960295
dengamma value 1.098094
dengamma value 1.032660
dengamma value 0.986475
dengamma value 0.936431
dengamma value 0.995148
dengamma value 1.018635
dengamma value 1.047368
11/24/2016 19:24:30:  Epoch[ 2 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.09136943 * 4800; err = 0.36125000 * 4800; time = 0.3697s; samplesPerSecond = 12982.3
dengamma value 0.995049
dengamma value 1.040118
dengamma value 1.050226
dengamma value 1.047880
dengamma value 1.039695
dengamma value 1.125882
dengamma value 1.085326
dengamma value 1.020683
dengamma value 1.060347
dengamma value 1.008885
dengamma value 1.070962
dengamma value 1.010869
dengamma value 0.981059
dengamma value 0.997017
dengamma value 1.060546
dengamma value 1.029930
dengamma value 1.022045
dengamma value 1.013874
dengamma value 1.013099
dengamma value 1.036016
dengamma value 1.021430
dengamma value 1.059550
11/24/2016 19:24:31:  Epoch[ 2 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08230385 * 6176; err = 0.34617876 * 6176; time = 0.4741s; samplesPerSecond = 13028.0
dengamma value 1.091687
dengamma value 1.054580
dengamma value 1.068426
dengamma value 0.982642
dengamma value 1.074483
dengamma value 1.042405
dengamma value 1.092267
dengamma value 0.957885
dengamma value 1.061578
dengamma value 1.029663
dengamma value 1.066020
dengamma value 1.014592
dengamma value 1.054690
dengamma value 0.998954
dengamma value 1.072480
dengamma value 1.037084
dengamma value 1.096243
dengamma value 1.132635
dengamma value 1.037480
dengamma value 0.965152
dengamma value 1.081118
dengamma value 1.048284
dengamma value 1.039851
11/24/2016 19:24:31:  Epoch[ 2 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.08998978 * 5534; err = 0.30791471 * 5534; time = 0.4716s; samplesPerSecond = 11733.7
dengamma value 1.060529
dengamma value 1.000414
dengamma value 0.986952
dengamma value 1.025660
dengamma value 1.110572
dengamma value 0.959939
dengamma value 1.067203
dengamma value 1.063095
dengamma value 1.050863
dengamma value 1.043348
dengamma value 1.104078
dengamma value 1.110926
dengamma value 1.051656
dengamma value 1.082978
dengamma value 1.039109
dengamma value 1.036769
dengamma value 1.051384
dengamma value 0.990762
dengamma value 1.061356
dengamma value 1.043009
dengamma value 0.998371
dengamma value 1.067152
11/24/2016 19:24:32:  Epoch[ 2 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.08287587 * 5936; err = 0.30626685 * 5936; time = 0.5377s; samplesPerSecond = 11040.5
dengamma value 0.915984
dengamma value 1.068776
dengamma value 1.072565
dengamma value 1.056520
dengamma value 1.075386
dengamma value 1.009733
dengamma value 1.070843
dengamma value 1.029459
dengamma value 1.029726
dengamma value 1.065580
dengamma value 0.908936
dengamma value 1.062620
dengamma value 1.117478
dengamma value 1.078478
dengamma value 1.000371
dengamma value 1.080604
dengamma value 1.089778
dengamma value 1.075679
dengamma value 1.092351
dengamma value 1.097066
dengamma value 1.055710
11/24/2016 19:24:32:  Epoch[ 2 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.08365445 * 5248; err = 0.32393293 * 5248; time = 0.4266s; samplesPerSecond = 12300.8
dengamma value 1.035227
dengamma value 1.028046
dengamma value 1.048955
dengamma value 1.015732
dengamma value 1.052929
dengamma value 1.062983
dengamma value 1.029182
dengamma value 0.996526
dengamma value 1.054619
dengamma value 1.036449
dengamma value 1.114403
dengamma value 1.067392
dengamma value 0.973700
dengamma value 1.076753
dengamma value 1.102290
dengamma value 1.028348
dengamma value 1.088040
dengamma value 1.098103
dengamma value 1.050145
dengamma value 1.027048
dengamma value 1.000811
dengamma value 1.058132
dengamma value 1.041159
dengamma value 1.055889
dengamma value 1.025248
dengamma value 1.067705
11/24/2016 19:24:33:  Epoch[ 2 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.08229460 * 6888; err = 0.30850755 * 6888; time = 0.5695s; samplesPerSecond = 12095.4
dengamma value 1.041106
dengamma value 1.069664
dengamma value 1.030431
dengamma value 1.045880
dengamma value 1.030824
dengamma value 1.029096
dengamma value 1.008572
dengamma value 1.083703
dengamma value 1.066985
dengamma value 1.027921
dengamma value 1.026236
dengamma value 1.091466
dengamma value 1.070343
dengamma value 1.011319
dengamma value 1.090688
dengamma value 1.007160
dengamma value 1.002410
dengamma value 1.107359
dengamma value 1.054784
dengamma value 1.032742
dengamma value 1.019634
dengamma value 1.021227
dengamma value 0.982746
dengamma value 1.038390
11/24/2016 19:24:33:  Epoch[ 2 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08657044 * 6572; err = 0.33703591 * 6572; time = 0.5217s; samplesPerSecond = 12597.5
dengamma value 0.994370
dengamma value 1.074123
dengamma value 1.015415
dengamma value 1.081716
dengamma value 1.047631
dengamma value 1.005121
dengamma value 1.011264
dengamma value 1.060514
dengamma value 1.040383
dengamma value 0.999052
dengamma value 1.052234
dengamma value 1.061897
dengamma value 1.068001
dengamma value 1.044555
dengamma value 1.020094
dengamma value 1.034750
dengamma value 1.024670
dengamma value 1.107010
dengamma value 0.998547
dengamma value 1.053649
dengamma value 1.048926
dengamma value 1.128838
dengamma value 1.072290
dengamma value 1.024949
11/24/2016 19:24:34:  Epoch[ 2 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.08643515 * 6622; err = 0.31425551 * 6622; time = 0.5714s; samplesPerSecond = 11589.2
dengamma value 1.027137
dengamma value 1.091871
dengamma value 1.016705
dengamma value 0.986396
dengamma value 1.035542
dengamma value 1.020436
dengamma value 0.946994
dengamma value 0.983166
dengamma value 0.939824
dengamma value 1.041023
dengamma value 1.067955
dengamma value 1.129261
dengamma value 1.107413
dengamma value 1.092192
dengamma value 1.025411
dengamma value 1.043051
dengamma value 1.001436
dengamma value 1.038574
dengamma value 1.028719
dengamma value 0.966598
dengamma value 1.045201
dengamma value 1.081102
dengamma value 1.032466
11/24/2016 19:24:34:  Epoch[ 2 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08797539 * 5824; err = 0.31850962 * 5824; time = 0.4412s; samplesPerSecond = 13199.4
dengamma value 0.970246
dengamma value 1.037569
dengamma value 1.106581
dengamma value 0.970027
dengamma value 1.009392
dengamma value 1.089476
dengamma value 1.057962
dengamma value 1.158356
dengamma value 1.039607
11/24/2016 19:24:35: Finished Epoch[ 2 of 3]: [Training] ce = 0.08465804 * 81776; err = 0.32420270 * 81776; totalSamplesSeen = 164350; learningRatePerSample = 2e-06; epochTime=6.74287s
11/24/2016 19:24:35: SGD: Saving checkpoint model '/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence.2'

11/24/2016 19:24:35: Starting Epoch 3: learning rate per sample = 0.000002  effective momentum = 0.995898  momentum as time constant = 2432.7 samples
minibatchiterator: epoch 2: frames [163840..245760] (first utterance at frame 163922), data subset 0 of 1, with 1 datapasses

11/24/2016 19:24:35: Starting minibatch loop.
dengamma value 1.077513
dengamma value 1.028340
dengamma value 1.070248
dengamma value 1.071597
dengamma value 1.082021
dengamma value 0.998957
dengamma value 1.026980
dengamma value 0.995208
dengamma value 1.017345
dengamma value 1.006024
dengamma value 1.039736
dengamma value 1.031318
dengamma value 1.024560
dengamma value 1.051309
dengamma value 1.052181
dengamma value 1.112069
dengamma value 1.014293
dengamma value 1.106634
dengamma value 1.019087
dengamma value 1.062165
dengamma value 1.000327
dengamma value 1.046828
dengamma value 1.095565
11/24/2016 19:24:35:  Epoch[ 3 of 3]-Minibatch[   1-  10, 0.12%]: ce = 0.08370350 * 5074; err = 0.33228222 * 5074; time = 0.4416s; samplesPerSecond = 11489.8
dengamma value 1.004078
dengamma value 1.094245
dengamma value 1.053059
dengamma value 1.067764
dengamma value 0.984299
dengamma value 0.990464
dengamma value 0.991427
dengamma value 0.995815
dengamma value 1.101860
dengamma value 1.064553
dengamma value 1.031844
dengamma value 1.020694
dengamma value 1.038801
dengamma value 1.038781
dengamma value 1.092339
dengamma value 1.085981
dengamma value 1.024932
dengamma value 1.043635
dengamma value 1.078083
dengamma value 0.967163
dengamma value 1.038559
dengamma value 1.020986
11/24/2016 19:24:36:  Epoch[ 3 of 3]-Minibatch[  11-  20, 0.24%]: ce = 0.08160169 * 7136; err = 0.31348094 * 7136; time = 0.5680s; samplesPerSecond = 12563.9
dengamma value 1.089676
dengamma value 1.004370
dengamma value 0.993380
dengamma value 1.007021
dengamma value 1.071273
dengamma value 1.022323
dengamma value 1.106520
dengamma value 0.991364
dengamma value 1.019610
dengamma value 1.057381
dengamma value 1.082189
dengamma value 1.048285
dengamma value 1.094091
dengamma value 1.019659
dengamma value 1.068419
dengamma value 1.017585
dengamma value 1.044954
dengamma value 1.009438
dengamma value 1.106436
dengamma value 1.111234
dengamma value 1.027988
dengamma value 0.997209
dengamma value 1.010093
11/24/2016 19:24:36:  Epoch[ 3 of 3]-Minibatch[  21-  30, 0.37%]: ce = 0.09327267 * 5504; err = 0.33975291 * 5504; time = 0.4660s; samplesPerSecond = 11810.2
dengamma value 1.049985
dengamma value 1.062557
dengamma value 1.049291
dengamma value 1.072867
dengamma value 1.051837
dengamma value 0.993665
dengamma value 1.059007
dengamma value 1.075324
dengamma value 1.016211
dengamma value 1.116792
dengamma value 1.038580
dengamma value 1.055062
dengamma value 1.049462
dengamma value 1.088850
dengamma value 0.978818
dengamma value 1.044560
dengamma value 0.999067
dengamma value 1.018055
dengamma value 0.942909
dengamma value 1.137021
dengamma value 1.061357
11/24/2016 19:24:37:  Epoch[ 3 of 3]-Minibatch[  31-  40, 0.49%]: ce = 0.08442294 * 6028; err = 0.32697412 * 6028; time = 0.5111s; samplesPerSecond = 11793.9
dengamma value 1.058254
dengamma value 1.094018
dengamma value 1.064477
dengamma value 1.063893
dengamma value 0.982159
dengamma value 0.973549
dengamma value 1.044369
dengamma value 0.993214
dengamma value 1.035570
dengamma value 1.098646
dengamma value 1.064655
dengamma value 1.025901
dengamma value 1.057474
dengamma value 1.046746
dengamma value 1.052440
dengamma value 0.999480
dengamma value 1.013308
dengamma value 1.133298
dengamma value 1.016483
dengamma value 1.040329
dengamma value 1.026609
11/24/2016 19:24:37:  Epoch[ 3 of 3]-Minibatch[  41-  50, 0.61%]: ce = 0.08535552 * 6028; err = 0.32879894 * 6028; time = 0.4754s; samplesPerSecond = 12679.4
dengamma value 1.027486
dengamma value 1.039581
dengamma value 1.017419
dengamma value 0.989204
dengamma value 1.046541
dengamma value 1.094041
dengamma value 1.083693
dengamma value 1.062080
dengamma value 0.976675
dengamma value 1.166793
dengamma value 0.987811
dengamma value 0.983069
dengamma value 1.061961
dengamma value 1.038545
dengamma value 1.036140
dengamma value 1.081587
dengamma value 0.994295
dengamma value 0.981019
dengamma value 1.060685
dengamma value 1.015593
dengamma value 1.051523
dengamma value 1.034331
dengamma value 1.002601
dengamma value 1.013739
11/24/2016 19:24:38:  Epoch[ 3 of 3]-Minibatch[  51-  60, 0.73%]: ce = 0.08529389 * 6782; err = 0.32881156 * 6782; time = 0.5389s; samplesPerSecond = 12584.1
dengamma value 1.062144
dengamma value 1.052580
dengamma value 1.100661
dengamma value 1.017306
dengamma value 1.086932
dengamma value 1.035741
dengamma value 1.092783
dengamma value 1.094628
dengamma value 1.072112
dengamma value 1.014484
dengamma value 1.080229
dengamma value 1.090802
dengamma value 0.987583
dengamma value 1.134912
dengamma value 1.126554
dengamma value 0.999848
dengamma value 1.046200
dengamma value 1.121253
dengamma value 1.060673
dengamma value 0.988734
dengamma value 1.012413
11/24/2016 19:24:38:  Epoch[ 3 of 3]-Minibatch[  61-  70, 0.85%]: ce = 0.07887115 * 5458; err = 0.29461341 * 5458; time = 0.4877s; samplesPerSecond = 11192.1
dengamma value 1.059115
dengamma value 1.020341
dengamma value 1.071918
dengamma value 1.051739
dengamma value 1.212426
dengamma value 1.089875
dengamma value 0.975985
dengamma value 1.071425
dengamma value 1.074963
dengamma value 1.044812
dengamma value 1.046808
dengamma value 1.074647
dengamma value 1.124182
dengamma value 1.144870
dengamma value 1.043787
dengamma value 1.064872
dengamma value 1.019997
dengamma value 1.016648
dengamma value 1.008102
dengamma value 1.104676
dengamma value 1.077710
dengamma value 1.109638
dengamma value 1.078114
dengamma value 1.090693
dengamma value 1.013600
11/24/2016 19:24:39:  Epoch[ 3 of 3]-Minibatch[  71-  80, 0.98%]: ce = 0.08031831 * 6610; err = 0.29425113 * 6610; time = 0.5458s; samplesPerSecond = 12110.5
dengamma value 1.071106
dengamma value 1.062858
dengamma value 1.104763
dengamma value 1.072281
dengamma value 1.061123
dengamma value 0.966847
dengamma value 1.026824
dengamma value 1.070768
dengamma value 1.079399
dengamma value 1.062158
dengamma value 1.038543
dengamma value 0.948246
dengamma value 1.120837
dengamma value 1.101894
dengamma value 1.009197
dengamma value 1.032486
dengamma value 0.907503
dengamma value 1.056175
dengamma value 1.105175
dengamma value 1.051911
dengamma value 1.023587
dengamma value 1.078703
dengamma value 1.037226
11/24/2016 19:24:39:  Epoch[ 3 of 3]-Minibatch[  81-  90, 1.10%]: ce = 0.08624770 * 5854; err = 0.31704817 * 5854; time = 0.4538s; samplesPerSecond = 12898.8
dengamma value 1.054835
dengamma value 1.132081
dengamma value 1.089594
dengamma value 0.882583
dengamma value 1.044460
dengamma value 1.054645
dengamma value 0.975773
dengamma value 1.074114
dengamma value 1.019529
dengamma value 1.021785
dengamma value 1.023403
dengamma value 1.010108
dengamma value 1.102825
dengamma value 1.059770
dengamma value 1.111265
dengamma value 1.072562
dengamma value 1.045677
dengamma value 1.101950
dengamma value 1.035794
dengamma value 0.970651
dengamma value 1.025532
dengamma value 1.061960
dengamma value 1.023248
11/24/2016 19:24:40:  Epoch[ 3 of 3]-Minibatch[  91- 100, 1.22%]: ce = 0.08990006 * 4674; err = 0.33140779 * 4674; time = 0.3853s; samplesPerSecond = 12130.3
dengamma value 0.988962
dengamma value 1.031365
dengamma value 1.056507
dengamma value 1.067448
dengamma value 1.029511
dengamma value 1.070507
dengamma value 1.040787
dengamma value 1.002095
dengamma value 1.116830
dengamma value 1.033054
dengamma value 1.030423
dengamma value 1.053696
dengamma value 1.065129
dengamma value 1.004694
dengamma value 0.920880
dengamma value 0.974601
dengamma value 0.999423
dengamma value 1.053662
dengamma value 1.027187
dengamma value 0.973645
dengamma value 1.081344
11/24/2016 19:24:40:  Epoch[ 3 of 3]-Minibatch[ 101- 110, 1.34%]: ce = 0.08247624 * 6248; err = 0.31994238 * 6248; time = 0.5002s; samplesPerSecond = 12491.4
dengamma value 0.965462
dengamma value 1.046590
dengamma value 1.044948
dengamma value 1.065925
dengamma value 1.133800
dengamma value 1.031227
dengamma value 1.049561
dengamma value 1.048773
dengamma value 1.096040
dengamma value 1.001146
dengamma value 1.004240
dengamma value 1.007200
dengamma value 1.050188
dengamma value 1.056445
dengamma value 0.991516
dengamma value 1.082690
dengamma value 1.110380
dengamma value 1.025826
dengamma value 1.042525
dengamma value 1.145444
dengamma value 1.102752
dengamma value 1.045883
dengamma value 1.079452
11/24/2016 19:24:41:  Epoch[ 3 of 3]-Minibatch[ 111- 120, 1.46%]: ce = 0.07827347 * 7094; err = 0.31561883 * 7094; time = 0.5766s; samplesPerSecond = 12302.9
dengamma value 1.044427
dengamma value 1.066994
dengamma value 1.049496
dengamma value 1.054198
dengamma value 1.044489
dengamma value 1.054655
dengamma value 1.051105
dengamma value 0.973185
dengamma value 0.990705
dengamma value 1.053892
dengamma value 1.064554
dengamma value 1.033569
dengamma value 1.008893
dengamma value 1.085517
dengamma value 0.992034
dengamma value 1.090332
dengamma value 1.054599
dengamma value 1.050178
dengamma value 1.027553
dengamma value 1.039339
dengamma value 1.055928
dengamma value 1.041476
11/24/2016 19:24:41:  Epoch[ 3 of 3]-Minibatch[ 121- 130, 1.59%]: ce = 0.08682572 * 6246; err = 0.31556196 * 6246; time = 0.5207s; samplesPerSecond = 11996.4
dengamma value 1.008790
dengamma value 1.051174
dengamma value 1.049594
dengamma value 1.072051
dengamma value 1.035597
dengamma value 0.967209
dengamma value 1.002120
dengamma value 1.119848
dengamma value 1.069093
dengamma value 0.988246
dengamma value 0.944602
dengamma value 1.061823
dengamma value 1.061823
11/24/2016 19:24:42: Finished Epoch[ 3 of 3]: [Training] ce = 0.08440978 * 81970; err = 0.32028791 * 81970; totalSamplesSeen = 246320; learningRatePerSample = 2e-06; epochTime=6.74932s
11/24/2016 19:24:42: SGD: Saving checkpoint model '/tmp/cntk-test-20161124192404.467155/Speech/DNN_SequenceTraining@release_gpu/models/cntkSpeech.sequence'

11/24/2016 19:24:42: Action "train" complete.

11/24/2016 19:24:42: __COMPLETED__